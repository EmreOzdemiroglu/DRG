# RAG & Chunk-Based Reading Durum Raporu

## âœ… HAZIR OLAN Ã–ZELLÄ°KLER

### 1. Chunk-Based Reading âœ…

**ModÃ¼l:** `drg/chunking/`

- âœ… **Token-Based Chunking**: 512-1024 token window desteÄŸi
- âœ… **Sentence-Based Chunking**: Sentence boundary aware
- âœ… **Overlap Strategy**: 10-20% overlap desteÄŸi
- âœ… **Metadata Injection**: chunk_id, sequence_index, origin_dataset
- âœ… **Boundary Detection**: Sentence/paragraph aware

**KullanÄ±m:**
```python
from drg.chunking import create_chunker

chunker = create_chunker(
    strategy="token_based",
    chunk_size=768,
    overlap_ratio=0.15,
)

chunks = chunker.chunk(
    text=long_text,
    origin_dataset="my_dataset",
    origin_file="document.txt",
)
```

### 2. Semantic Context (Embedding) âœ…

**ModÃ¼l:** `drg/embedding/`

- âœ… **OpenAI Embeddings**: text-embedding-3-small/large
- âœ… **Gemini Embeddings**: embedding-001
- âœ… **OpenRouter**: Unified API
- âœ… **Local Models**: sentence-transformers
- âœ… **Batch Processing**: embed_batch() desteÄŸi

**KullanÄ±m:**
```python
from drg.embedding import create_embedding_provider

provider = create_embedding_provider(
    provider="gemini",
    model="models/embedding-001",
)

embeddings = provider.embed_batch(chunk_texts)
```

### 3. Vector Store âœ…

**ModÃ¼l:** `drg/vector_store/`

- âœ… **ChromaDB**: Production-ready implementation
- âœ… **Interface**: Pluggable vector store abstraction
- âœ… **Metadata Indexing**: Chunk metadata ile birlikte
- âœ… **Similarity Search**: Cosine similarity

**KullanÄ±m:**
```python
from drg.vector_store import create_vector_store

vector_store = create_vector_store(
    store_type="chroma",
    collection_name="my_chunks",
)

vector_store.add(
    embeddings=chunk_embeddings,
    metadata=chunk_metadata,
    ids=chunk_ids,
)
```

### 4. RAG Retrieval âœ…

**ModÃ¼l:** `drg/retrieval/rag.py`

- âœ… **Vector Similarity Search**: Semantic retrieval
- âœ… **Knowledge Graph Context**: KG subgraph entegrasyonu
- âœ… **Metadata Filtering**: Entity/topic filtering
- âœ… **RetrievalContext**: Chunks + KG context birleÅŸik dÃ¶ndÃ¼rme

**KullanÄ±m:**
```python
from drg.retrieval import create_rag_retriever

rag = create_rag_retriever(
    embedding_provider=provider,
    vector_store=vector_store,
    knowledge_graph=kg,
    include_kg_context=True,  # âœ… KG context entegrasyonu
)

context = rag.retrieve(query="What products does Apple produce?", k=10)

# Context iÃ§inde:
# - context.chunks: Retrieved chunks
# - context.kg_subgraph: Related KG subgraph
# - context.entities: Related entities
# - context.relationships: Related relationships
```

### 5. Knowledge Graph Context Integration âœ…

**Ã–zellik:** Chunk-based reading sÄ±rasÄ±nda KG context kaybÄ±nÄ± Ã¶nler

- âœ… **Automatic KG Context Extraction**: Retrieved chunks'tan entity'leri Ã§Ä±karÄ±r
- âœ… **Subgraph Building**: Ä°lgili entity'lerin subgraph'Ä±nÄ± oluÅŸturur
- âœ… **Relationship Enrichment**: Ä°lgili relationship'leri ekler

**NasÄ±l Ã‡alÄ±ÅŸÄ±r:**
1. Chunk'lar retrieve edilir (vector similarity)
2. Chunk'lardan entity'ler extract edilir
3. KG'de bu entity'lerin subgraph'Ä± bulunur
4. Context'e hem chunks hem de KG subgraph eklenir

## ðŸ“Š TAM PIPELINE Ã–RNEÄžÄ°

**Dosya:** `examples/pipeline_example.py`

Tam pipeline ÅŸu adÄ±mlarÄ± iÃ§erir:
1. âœ… Chunking (text â†’ chunks)
2. âœ… KG Extraction (text â†’ entities, relations)
3. âœ… Embedding (chunks â†’ embeddings)
4. âœ… Vector Store (embeddings â†’ storage)
5. âœ… RAG Retrieval (query â†’ chunks + KG context)

## ðŸŽ¯ KULLANIM Ã–RNEÄžÄ°

```python
from drg.chunking import create_chunker
from drg.embedding import create_embedding_provider
from drg.vector_store import create_vector_store
from drg.retrieval import create_rag_retriever
from drg.extract import extract_typed
from drg.schema import DRGSchema, Entity, Relation

# 1. Chunking
chunker = create_chunker(strategy="token_based", chunk_size=768)
chunks = chunker.chunk(text=long_text, origin_dataset="demo")

# 2. KG Extraction
schema = DRGSchema(entities=[...], relations=[...])
entities, triples = extract_typed(text, schema)
kg = KG.from_typed(entities, triples)

# 3. Embedding
provider = create_embedding_provider(provider="gemini")
embeddings = provider.embed_batch([chunk.text for chunk in chunks])

# 4. Vector Store
vector_store = create_vector_store(store_type="chroma")
vector_store.add(embeddings, [chunk.to_dict() for chunk in chunks])

# 5. RAG Retrieval with KG Context
rag = create_rag_retriever(
    embedding_provider=provider,
    vector_store=vector_store,
    knowledge_graph=kg,
    include_kg_context=True,  # âœ… KG context aktif
)

context = rag.retrieve(query="What products does Apple produce?", k=10)

# Context iÃ§inde:
# - context.chunks: Semantic similar chunks
# - context.kg_subgraph: Related KG nodes/edges
# - context.entities: Related entities
# - context.relationships: Related relationships
```

## âœ… SONUÃ‡

**TÃ¼m Ã¶zellikler hazÄ±r ve Ã§alÄ±ÅŸÄ±yor:**

1. âœ… Chunk-based reading
2. âœ… Semantic context (embedding)
3. âœ… RAG retrieval
4. âœ… Knowledge graph context entegrasyonu
5. âœ… Tam pipeline Ã¶rneÄŸi

**Test iÃ§in:**
```bash
python examples/pipeline_example.py
```

