# DRG Projesi: KapsamlÄ± Proje DokÃ¼mantasyonu

## ğŸ“‹ Ä°Ã§indekiler

1. [Proje Genel BakÄ±ÅŸ](#proje-genel-bakÄ±ÅŸ)
2. [Temel Kavramlar](#temel-kavramlar)
3. [Proje Felsefesi ve TasarÄ±m Prensipleri](#proje-felsefesi-ve-tasarÄ±m-prensipleri)
4. [Proje YapÄ±sÄ±](#proje-yapÄ±sÄ±)
5. [Declarative YapÄ±](#declarative-yapÄ±)
6. [Pipeline Mimarisi](#pipeline-mimarisi)
7. [BileÅŸenler ve Metodlar](#bileÅŸenler-ve-metodlar)
8. [DiÄŸer KG Sistemlerinden FarklarÄ±](#diÄŸer-kg-sistemlerinden-farklarÄ±)
9. [KullanÄ±m Ã–rnekleri](#kullanÄ±m-Ã¶rnekleri)
10. [GeliÅŸtirme ve KatkÄ±da Bulunma](#geliÅŸtirme-ve-katkÄ±da-bulunma)

---

## Proje Genel BakÄ±ÅŸ

### DRG Nedir?

**DRG (Declarative Relationship Generation)**, metinlerden bilgi grafiÄŸi (Knowledge Graph) Ã§Ä±karÄ±mÄ± yapmak iÃ§in tasarlanmÄ±ÅŸ, dataset-agnostic (veri kaynaÄŸÄ±ndan baÄŸÄ±msÄ±z) bir Python kÃ¼tÃ¼phanesidir. DRG, modern Large Language Model (LLM) teknolojilerini kullanarak, sadece ÅŸema tanÄ±mlayarak otomatik olarak entity (varlÄ±k) ve relation (iliÅŸki) Ã§Ä±karÄ±mÄ± yapar.

### Projenin Temel AmacÄ±

DRG projesi, aÅŸaÄŸÄ±daki temel amaÃ§lara hizmet eder:

1. **Declarative (Deklaratif) YaklaÅŸÄ±m**: KullanÄ±cÄ±lar "ne" istediklerini tanÄ±mlar, sistem "nasÄ±l" yapÄ±lacaÄŸÄ±nÄ± otomatik olarak halleder.

2. **Dataset-Agnostic TasarÄ±m**: Herhangi bir veri kaynaÄŸÄ±ndan (metin, PDF, JSON, vb.) baÄŸÄ±msÄ±z olarak Ã§alÄ±ÅŸÄ±r.

3. **GraphRAG DesteÄŸi**: Sadece klasik RAG (Retrieval-Augmented Generation) deÄŸil, aynÄ± zamanda GraphRAG (Graph-based RAG) yapÄ±sÄ±nÄ± da destekler.

4. **Research-Grade Kalite**: Akademik araÅŸtÄ±rmalar ve yayÄ±nlar iÃ§in uygun, yÃ¼ksek kaliteli kod yapÄ±sÄ±.

5. **Community Publication-Ready**: Topluluk tarafÄ±ndan kullanÄ±lmaya ve yayÄ±nlanmaya hazÄ±r bir sistem.

### Projenin Ã–zellikleri

- âœ… **Declarative Schema**: Sadece entity tipleri ve iliÅŸkileri tanÄ±mlayÄ±n, gerisini DRG halletsin
- âœ… **Otomatik Schema Generation**: Metinden otomatik olarak EnhancedDRGSchema oluÅŸturma (`generate_schema_from_text`)
- âœ… **DSPy Entegrasyonu**: Modern LLM'lerle Ã§alÄ±ÅŸan gÃ¼Ã§lÃ¼ extraction pipeline
- âœ… **Enhanced Schema**: EntityType (properties, examples), RelationGroup (semantic grouping), Relation (description, detail) ile zengin ÅŸema tanÄ±mlarÄ±
- âœ… **Chunk-based KG Extraction**: Her chunk Ã¼zerinde baÄŸÄ±msÄ±z extraction, sonuÃ§larÄ±n birleÅŸtirilmesi
- âœ… **Schema Validation**: Extraction sonuÃ§larÄ±nÄ±n ÅŸemaya uygunluÄŸunun otomatik kontrolÃ¼
- âœ… **Otomatik LLM KonfigÃ¼rasyonu**: Environment variable'lardan otomatik model ve API key yÃ¶netimi
- âœ… **GraphRAG Pipeline**: Chunking â†’ KG Extraction â†’ Embedding â†’ Clustering â†’ Community Reports â†’ Retrieval
- âœ… **Clustering DesteÄŸi**: Louvain, Leiden, Spectral algoritmalarÄ± ile community detection
- âœ… **Community Reports**: Her cluster iÃ§in otomatik Ã¶zet raporlar (top actors, top relationships, themes)
- âœ… **Preset-based Chunking**: "graphrag" gibi preset'lerle kolay chunking konfigÃ¼rasyonu
- âœ… **Multi-Provider DesteÄŸi**: OpenAI, Gemini, Anthropic, OpenRouter, Perplexity, Ollama
- âœ… **FastAPI Web Server**: RESTful API ve interaktif web UI ile KG gÃ¶rselleÅŸtirme
- âœ… **Graph Visualization**: Cytoscape.js tabanlÄ± interaktif graph gÃ¶rselleÅŸtirme (zoom, pan, community coloring)
- âœ… **Query Provenance**: Query â†’ chunks â†’ community â†’ summary â†’ answer provenance chain tracking
- âœ… **Neo4j Integration**: Knowledge graph'Ä± Neo4j'e senkronize etme ve persistence
- âœ… **MCP API**: Agent interface iÃ§in Model Context Protocol desteÄŸi
- âœ… **Optimizer DesteÄŸi**: DSPy optimizer'larÄ± ile iterative learning
- âœ… **Self-loop Filtering**: KG'de self-loop edge'lerin otomatik filtrelenmesi
- âœ… **Isolated Node Filtering**: Visualization'da baÄŸlantÄ±sÄ±z node'larÄ±n otomatik filtrelenmesi

---

## Temel Kavramlar

### Knowledge Graph (Bilgi GrafiÄŸi) Nedir?

**Knowledge Graph (KG)**, bilgileri yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir ÅŸekilde temsil eden bir graf yapÄ±sÄ±dÄ±r. KG'de:

- **Node (DÃ¼ÄŸÃ¼m)**: Entity'ler (varlÄ±klar) - Ã¶rneÄŸin: "Apple", "Steve Jobs", "iPhone"
- **Edge (Kenar)**: Relation'lar (iliÅŸkiler) - Ã¶rneÄŸin: "Apple â†’ produces â†’ iPhone"

KG'ler, bilgileri iliÅŸkisel bir yapÄ±da sakladÄ±ÄŸÄ± iÃ§in, sadece metin aramasÄ±ndan daha gÃ¼Ã§lÃ¼ sorgulama ve Ã§Ä±karÄ±m yapÄ±lmasÄ±na olanak tanÄ±r.

### Entity (VarlÄ±k) Nedir?

**Entity**, metinde bahsedilen somut veya soyut kavramlardÄ±r. Ã–rneÄŸin:
- **KiÅŸiler**: "Steve Jobs", "Tim Cook"
- **Åirketler**: "Apple Inc.", "Google"
- **ÃœrÃ¼nler**: "iPhone", "iPad"
- **Lokasyonlar**: "Cupertino", "California"

### Relation (Ä°liÅŸki) Nedir?

**Relation**, iki entity arasÄ±ndaki baÄŸlantÄ±yÄ± temsil eder. Ã–rneÄŸin:
- "Apple â†’ produces â†’ iPhone" (Apple, iPhone Ã¼retir)
- "Steve Jobs â†’ founded_by â†’ Apple" (Steve Jobs, Apple'Ä± kurdu)
- "Tim Cook â†’ ceo_of â†’ Apple" (Tim Cook, Apple'Ä±n CEO'sudur)

### Chunking (ParÃ§alama) Nedir?

**Chunking**, uzun metinleri daha kÃ¼Ã§Ã¼k, iÅŸlenebilir parÃ§alara bÃ¶lme iÅŸlemidir. LLM'ler genellikle sÄ±nÄ±rlÄ± token kapasitesine sahip olduÄŸu iÃ§in, uzun metinler Ã¶nce chunk'lara bÃ¶lÃ¼nÃ¼r, sonra her chunk Ã¼zerinde iÅŸlem yapÄ±lÄ±r.

DRG'de chunking stratejileri:
- **Token-based**: Token sayÄ±sÄ±na gÃ¶re bÃ¶lme
- **Sentence-based**: CÃ¼mle sÄ±nÄ±rlarÄ±na gÃ¶re bÃ¶lme
- **Semantic**: Anlamsal benzerliÄŸe gÃ¶re bÃ¶lme

### Embedding (VektÃ¶rleÅŸtirme) Nedir?

**Embedding**, metinleri sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemidir. Bu vektÃ¶rler, metinlerin anlamsal benzerliÄŸini Ã¶lÃ§mek iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, "Apple" ve "iPhone" kelimeleri birbirine yakÄ±n vektÃ¶rlerle temsil edilir.

### RAG (Retrieval-Augmented Generation) Nedir?

**RAG**, LLM'lerin bilgiyi gerÃ§ek zamanlÄ± olarak retrieve (getirme) edip kullanmasÄ±na olanak tanÄ±yan bir yaklaÅŸÄ±mdÄ±r. RAG'de:
1. Metinler chunk'lara bÃ¶lÃ¼nÃ¼r ve embed edilir
2. Query (sorgu) embed edilir
3. Query'ye en benzer chunk'lar bulunur (vector similarity)
4. Bu chunk'lar LLM'e context olarak verilir
5. LLM, bu context'i kullanarak cevap Ã¼retir

### GraphRAG Nedir?

**GraphRAG**, RAG'in geliÅŸmiÅŸ bir versiyonudur. GraphRAG'de:
1. Metinlerden Knowledge Graph oluÅŸturulur
2. Query'den seed entity'ler bulunur (embedding kullanarak)
3. Graph traversal (graf gezinme) ile ilgili entity'ler bulunur
4. Community reports (topluluk raporlarÄ±) oluÅŸturulur
5. Bu bilgiler LLM'e context olarak verilir

GraphRAG'Ä±n avantajlarÄ±:
- Multi-hop reasoning (Ã§ok adÄ±mlÄ± Ã§Ä±karÄ±m) yapabilir
- Entity relationships explicit olarak kullanÄ±lÄ±r
- Graph topology'den bilgi Ã§Ä±karÄ±lÄ±r

### Declarative (Deklaratif) Programlama Nedir?

**Declarative programming**, "ne" istediÄŸinizi tanÄ±mladÄ±ÄŸÄ±nÄ±z, sistemin "nasÄ±l" yapÄ±lacaÄŸÄ±nÄ± otomatik olarak hallettiÄŸi bir programlama paradigmasÄ±dÄ±r.

**Imperative (Emirsel) YaklaÅŸÄ±m** (Geleneksel):
```python
# NasÄ±l yapÄ±lacaÄŸÄ±nÄ± adÄ±m adÄ±m tanÄ±mlarsÄ±nÄ±z
text = "Apple produces iPhone"
# 1. Metni parse et
# 2. Entity'leri bul
# 3. Relation'larÄ± bul
# 4. KG oluÅŸtur
```

**Declarative (Deklaratif) YaklaÅŸÄ±m** (DRG):
```python
# Sadece ne istediÄŸinizi tanÄ±mlarsÄ±nÄ±z
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)
# Sistem otomatik olarak extraction yapar
entities, triples = extract_typed(text, schema)
```

---

## Proje Felsefesi ve TasarÄ±m Prensipleri

### 1. Monolithic-Modular Mimarisi

DRG, **monolithic-modular** bir mimari kullanÄ±r:

- **Monolithic**: TÃ¼m bileÅŸenler aynÄ± codebase iÃ§inde, tek bir deployment unit
- **Modular**: Her bileÅŸen baÄŸÄ±msÄ±z interface'ler Ã¼zerinden iletiÅŸim kurar
- **Loose Coupling**: BileÅŸenler arasÄ± baÄŸÄ±mlÄ±lÄ±klar minimal ve aÃ§Ä±kÃ§a tanÄ±mlÄ±dÄ±r
- **High Cohesion**: Ä°lgili fonksiyonellik aynÄ± modÃ¼lde gruplanÄ±r

Bu yaklaÅŸÄ±mÄ±n avantajlarÄ±:
- Kolay deployment (tek bir paket)
- ModÃ¼ler test edilebilirlik
- Esnek bileÅŸen deÄŸiÅŸimi

### 2. Dataset-Agnostic TasarÄ±m

DRG, herhangi bir veri kaynaÄŸÄ±ndan baÄŸÄ±msÄ±z olarak Ã§alÄ±ÅŸÄ±r:

- **Abstraction Layers**: Veri kaynaÄŸÄ±, chunking stratejisi ve embedding modeli arasÄ±nda net arayÃ¼zler
- **Pluggable Components**: Her bileÅŸen baÄŸÄ±msÄ±z olarak deÄŸiÅŸtirilebilir ve test edilebilir
- **Metadata Preservation**: Her chunk, orijin veri kaynaÄŸÄ± ve iÅŸlem geÃ§miÅŸi hakkÄ±nda zengin metadata taÅŸÄ±r
- **Domain Adaptation**: Domain-specific optimizasyonlar, core pipeline'Ä± deÄŸiÅŸtirmeden eklenebilir

### 3. Interface-First Design

Her bileÅŸen iÃ§in Ã¶nce interface tanÄ±mlanÄ±r, sonra implementation yapÄ±lÄ±r:

```python
# Interface
class EmbeddingProvider(ABC):
    @abstractmethod
    def embed(self, text: str) -> List[float]:
        pass

# Implementation
class OpenAIEmbeddingProvider(EmbeddingProvider):
    def embed(self, text: str) -> List[float]:
        # Implementation
        pass
```

### 4. Dependency Injection

Hard dependencies yerine dependency injection kullanÄ±lÄ±r:

```python
# Bad
class Chunker:
    def __init__(self):
        self.tokenizer = TiktokenTokenizer()  # Hard dependency

# Good
class Chunker:
    def __init__(self, tokenizer: Tokenizer):
        self.tokenizer = tokenizer  # Injected dependency
```

---

## Proje YapÄ±sÄ±

### KlasÃ¶r YapÄ±sÄ±

Proje yapÄ±sÄ±, **monolithic-modular** mimari prensibine uygun olarak dÃ¼zenlenmiÅŸtir. TÃ¼m kod `drg/` modÃ¼lÃ¼ altÄ±nda toplanmÄ±ÅŸ, ancak her bileÅŸen baÄŸÄ±msÄ±z modÃ¼ller halinde organize edilmiÅŸtir.

```
DRG/                                    # Proje root dizini
â”‚
â”œâ”€â”€ ğŸ“¦ drg/                             # Ana Python modÃ¼lÃ¼ (Core Library)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¯ Core Components              # Temel bileÅŸenler
â”‚   â”‚   â”œâ”€â”€ __init__.py                 # Public API exports
â”‚   â”‚   â”œâ”€â”€ schema.py                   # Schema tanÄ±mlarÄ± (Entity, Relation, DRGSchema, EnhancedDRGSchema)
â”‚   â”‚   â”œâ”€â”€ extract.py                  # DSPy-based KG extraction (KGExtractor, generate_schema_from_text)
â”‚   â”‚   â”œâ”€â”€ graph.py                    # Legacy KG class (geriye dÃ¶nÃ¼k uyumluluk iÃ§in)
â”‚   â”‚   â””â”€â”€ cli.py                      # Komut satÄ±rÄ± arayÃ¼zÃ¼
â”‚   â”‚
â”‚   â”œâ”€â”€ âœ‚ï¸  chunking/                   # Metin ParÃ§alama KatmanÄ±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ strategies.py               # Chunking stratejileri (token, sentence, semantic)
â”‚   â”‚   â””â”€â”€ validators.py               # Chunk doÄŸrulama ve validasyon
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ§® embedding/                   # Embedding SaÄŸlayÄ±cÄ±larÄ±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ providers.py                # Embedding provider interface
â”‚   â”‚   â”œâ”€â”€ openai.py                   # OpenAI embedding provider
â”‚   â”‚   â”œâ”€â”€ gemini.py                   # Google Gemini embedding provider
â”‚   â”‚   â”œâ”€â”€ openrouter.py               # OpenRouter embedding provider
â”‚   â”‚   â””â”€â”€ local.py                    # Local model provider (sentence-transformers)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ’¾ vector_store/                # VektÃ¶r VeritabanÄ± SoyutlamasÄ±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ interface.py                # Vector store interface
â”‚   â”‚   â”œâ”€â”€ chroma.py                   # ChromaDB implementation
â”‚   â”‚   â”œâ”€â”€ qdrant.py                   # Qdrant implementation
â”‚   â”‚   â”œâ”€â”€ faiss.py                    # FAISS implementation
â”‚   â”‚   â””â”€â”€ factory.py                  # Factory pattern for vector stores
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ•¸ï¸  graph/                      # Knowledge Graph KatmanÄ±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ kg_core.py                  # EnhancedKG, KGNode, KGEdge, Cluster sÄ±nÄ±flarÄ±
â”‚   â”‚   â”œâ”€â”€ visualization.py            # KG gÃ¶rselleÅŸtirme (Mermaid, PyVis)
â”‚   â”‚   â”œâ”€â”€ visualization_adapter.py    # Web viz adapters (Cytoscape.js, vis-network, D3.js)
â”‚   â”‚   â”œâ”€â”€ community_report.py         # Community report generation
â”‚   â”‚   â”œâ”€â”€ neo4j_exporter.py           # Neo4j persistence layer
â”‚   â”‚   â”œâ”€â”€ schema_generator.py         # Dataset-agnostic schema generation
â”‚   â”‚   â””â”€â”€ relationship_model.py       # Relationship type classification
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ” retrieval/                   # Retrieval KatmanÄ±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag.py                      # Classic RAG retrieval (vector similarity)
â”‚   â”‚   â”œâ”€â”€ graphrag.py                 # GraphRAG retrieval (KG traversal + community reports)
â”‚   â”‚   â”œâ”€â”€ drg_search.py               # DRG search algorithms
â”‚   â”‚   â””â”€â”€ hybrid.py                   # Hybrid RAG + GraphRAG retriever
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ”— clustering/                  # Clustering KatmanÄ±
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ algorithms.py               # Clustering algoritmalarÄ± (Louvain, Leiden, Spectral)
â”‚   â”‚   â””â”€â”€ summarization.py            # Cluster Ã¶zetleme (community reports)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ›ï¸  optimizer/                  # DSPy Optimizer ModÃ¼lÃ¼
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ optimizer.py                # DRGOptimizer class
â”‚   â”‚   â””â”€â”€ metrics.py                  # Evaluation metrics (precision, recall, F1)
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸŒ api/                         # FastAPI Web Server
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ server.py                   # FastAPI app ve REST API endpoints
â”‚   â”‚   â”œâ”€â”€ templates/                  # HTML templates
â”‚   â”‚   â”‚   â””â”€â”€ index.html              # Cytoscape.js interaktif graph visualization UI
â”‚   â”‚   â””â”€â”€ static/                     # Static dosyalar (CSS, JavaScript)
â”‚   â”‚
â”‚   â””â”€â”€ mcp_api.py                      # Model Context Protocol (MCP) API interface
â”‚
â”œâ”€â”€ ğŸ“š docs/                            # DokÃ¼mantasyon (KOD YOK, SADECE MARKDOWN)
â”‚   â”œâ”€â”€ PROJECT_OVERVIEW.md             # Bu dosya - KapsamlÄ± proje dokÃ¼mantasyonu
â”‚   â”œâ”€â”€ pipeline_overview.md            # Pipeline mimarisi ve akÄ±ÅŸ diyagramlarÄ±
â”‚   â”œâ”€â”€ schema_design.md                # Schema tasarÄ±m prensipleri
â”‚   â”œâ”€â”€ chunking_strategy.md            # Chunking stratejileri ve best practices
â”‚   â”œâ”€â”€ drg_search.md                   # DRG search algoritmalarÄ±
â”‚   â”œâ”€â”€ clustering_summarization.md     # Clustering ve community report generation
â”‚   â”œâ”€â”€ optimizer_design.md             # DSPy optimizer entegrasyonu
â”‚   â”œâ”€â”€ relationship_model.md           # Relationship classification modeli
â”‚   â””â”€â”€ mcp_integration.md              # MCP API entegrasyonu
â”‚
â”œâ”€â”€ ğŸ’¡ examples/                        # KullanÄ±m Ã–rnekleri
â”‚   â”œâ”€â”€ graphrag_pipeline_example.py    # Tam GraphRAG pipeline Ã¶rneÄŸi (Ana Ã¶rnek)
â”‚   â”œâ”€â”€ api_server_example.py           # FastAPI server baÅŸlatma Ã¶rneÄŸi
â”‚   â”œâ”€â”€ mcp_demo.py                     # MCP API demo
â”‚   â””â”€â”€ optimizer_demo.py               # DSPy optimizer demo
â”‚
â”œâ”€â”€ ğŸ§ª tests/                           # Test Suite
â”‚   â”œâ”€â”€ test_basic.py                   # Temel testler (tÃ¼m provider'lar iÃ§in)
â”‚   â””â”€â”€ multi_dataset/                  # Multi-dataset evaluation
â”‚       â””â”€â”€ evaluation.py               # Ã‡oklu veri seti deÄŸerlendirme testleri
â”‚
â”œâ”€â”€ ğŸ“¥ inputs/                          # GiriÅŸ DosyalarÄ± (Test Verileri)
â”‚   â”œâ”€â”€ 1example_text.txt               # Ã–rnek 1: Metin dosyasÄ±
â”‚   â”œâ”€â”€ 1example_schema.json            # Ã–rnek 1: Schema (opsiyonel - yoksa otomatik oluÅŸturulur)
â”‚   â”œâ”€â”€ 2example_text.txt               # Ã–rnek 2: Metin dosyasÄ±
â”‚   â”œâ”€â”€ 3example_text.txt               # Ã–rnek 3: Metin dosyasÄ±
â”‚   â”œâ”€â”€ 3example_schema.json            # Ã–rnek 3: Schema
â”‚   â”œâ”€â”€ 4example_text.txt               # Ã–rnek 4: Metin dosyasÄ±
â”‚   â””â”€â”€ 4example_schema.json            # Ã–rnek 4: Schema
â”‚
â”œâ”€â”€ ğŸ“¤ outputs/                         # Ã‡Ä±ktÄ± DosyalarÄ± (Pipeline SonuÃ§larÄ±)
â”‚   â”œâ”€â”€ {example_name}_schema.json      # OluÅŸturulan/gÃ¼ncellenen schema
â”‚   â”œâ”€â”€ {example_name}_kg.json          # Knowledge Graph (EnhancedKG formatÄ±nda)
â”‚   â”œâ”€â”€ {example_name}_community_reports.json  # Community/cluster raporlarÄ±
â”‚   â””â”€â”€ {example_name}_summary.json     # Pipeline Ã¶zeti (istatistikler)
â”‚
â”œâ”€â”€ ğŸš€ Scripts                          # YardÄ±mcÄ± Scriptler
â”‚   â”œâ”€â”€ start_api_server.sh             # API server baÅŸlatma scripti (GEMINI_API_KEY otomatik export)
â”‚   â””â”€â”€ restart_api_server.sh           # API server yeniden baÅŸlatma scripti (port 8000 temizleme)
â”‚
â”œâ”€â”€ ğŸ“„ Configuration & Docs             # KonfigÃ¼rasyon ve DokÃ¼mantasyon DosyalarÄ±
â”‚   â”œâ”€â”€ README.md                       # Proje ana README dosyasÄ±
â”‚   â”œâ”€â”€ README_API.md                   # API server dokÃ¼mantasyonu
â”‚   â”œâ”€â”€ SETUP.md                        # Kurulum talimatlarÄ±
â”‚   â”œâ”€â”€ QUICK_START.md                  # HÄ±zlÄ± baÅŸlangÄ±Ã§ rehberi
â”‚   â”œâ”€â”€ pyproject.toml                  # Proje konfigÃ¼rasyonu (Python packaging)
â”‚   â”œâ”€â”€ requirements.txt                # Python baÄŸÄ±mlÄ±lÄ±klarÄ±
â”‚   â””â”€â”€ LICENSE                         # Lisans dosyasÄ±
â”‚
â””â”€â”€ uv.lock                             # UV package manager lock file (opsiyonel)
```

#### YapÄ± AÃ§Ä±klamalarÄ±

**ğŸ“¦ drg/**: Ana Python modÃ¼lÃ¼. TÃ¼m core functionality burada toplanmÄ±ÅŸtÄ±r. ModÃ¼ler yapÄ±, ancak tek bir paket olarak deploy edilir (monolithic-modular mimari).

**ğŸ¯ Core Components**: Schema tanÄ±mlarÄ±, extraction logic, CLI interface gibi temel bileÅŸenler.

**Katmanlar (Layers)**: Pipeline'Ä±n adÄ±mlarÄ±na karÅŸÄ±lÄ±k gelen modÃ¼ller:
- **chunking/**: Metin parÃ§alama
- **embedding/**: VektÃ¶rleÅŸtirme
- **graph/**: KG oluÅŸturma ve yÃ¶netimi
- **retrieval/**: Bilgi eriÅŸimi (RAG, GraphRAG)
- **clustering/**: Topluluk tespiti

**ğŸŒ api/**: FastAPI web server ve interaktif graph visualization UI.

**ğŸ“š docs/**: Teknik dokÃ¼mantasyon. Kod iÃ§ermez, sadece tasarÄ±m ve mimari dokÃ¼mantasyonu.

**ğŸ’¡ examples/**: KullanÄ±m Ã¶rnekleri. Yeni kullanÄ±cÄ±lar iÃ§in baÅŸlangÄ±Ã§ noktasÄ±.

### ModÃ¼l AÃ§Ä±klamalarÄ±

#### `drg/schema.py`
Schema tanÄ±mlarÄ± iÃ§in temel sÄ±nÄ±flar:
- `Entity`: Basit entity tanÄ±mÄ±
- `Relation`: Relation tanÄ±mÄ± (name, source, target, description, detail)
  - `description`: BaÄŸlantÄ± sebebi/tÃ¼rÃ¼ aÃ§Ä±klamasÄ±
  - `detail`: BaÄŸlantÄ± detayÄ± (tek cÃ¼mleyle neden baÄŸlantÄ±lÄ± olduÄŸu)
- `DRGSchema`: Legacy schema class (backward compatibility)
- `EntityType`: GeliÅŸmiÅŸ entity tanÄ±mÄ± (name, description, examples, properties)
- `RelationGroup`: Ä°liÅŸkili relation'larÄ± semantic olarak gruplama
- `EnhancedDRGSchema`: GeliÅŸmiÅŸ schema class (entity_types, relation_groups, auto_discovery)

#### `drg/extract.py`
DSPy kullanarak entity ve relation extraction:
- `KGExtractor`: Ana extraction class (chunk-based processing iÃ§in kullanÄ±lÄ±r)
- `extract_typed()`: Typed entity ve relation extraction
- `extract_triples()`: Sadece relation extraction (backward compatibility)
- `generate_schema_from_text()`: Metinden otomatik EnhancedDRGSchema oluÅŸturma
- `_configure_llm_auto()`: Otomatik LLM konfigÃ¼rasyonu (OpenRouter, OpenAI, vb.)

#### `drg/chunking/`
Metin parÃ§alama stratejileri:
- `TokenBasedChunker`: Token sayÄ±sÄ±na gÃ¶re chunking
- `SentenceBasedChunker`: CÃ¼mle sÄ±nÄ±rlarÄ±na gÃ¶re chunking
- `ChunkValidator`: Chunk doÄŸrulama
- `create_chunker()`: Factory function (preset desteÄŸi ile)
  - Preset'ler: "graphrag", "medium"

#### `drg/embedding/`
Embedding provider'larÄ±:
- `OpenAIEmbeddingProvider`: OpenAI embedding'leri
- `GeminiEmbeddingProvider`: Google Gemini embedding'leri
- `OpenRouterEmbeddingProvider`: OpenRouter embedding'leri
- `LocalEmbeddingProvider`: Local model embedding'leri (sentence-transformers)

#### `drg/graph/kg_core.py`
Enhanced Knowledge Graph yapÄ±sÄ±:
- `KGNode`: Graph node (id, type, properties, metadata, embedding)
- `KGEdge`: Graph edge (source, target, relationship_type, relationship_detail, metadata)
- `Cluster`: Cluster tanÄ±mÄ± (id, node_ids, metadata)
- `EnhancedKG`: Ana KG class (nodes, edges, clusters, community reports)

#### `drg/retrieval/`
Retrieval stratejileri:
- `RAGRetriever`: Classic RAG (vector similarity search)
- `GraphRAGRetriever`: GraphRAG (KG traversal + community reports)
- `DRGSearch`: DRG search algorithms
- `HybridRetriever`: RAG + GraphRAG hybrid

#### `drg/clustering/`
Clustering algoritmalarÄ±:
- `LouvainClustering`: Louvain community detection (python-louvain gerekli)
- `LeidenClustering`: Leiden algorithm (leidenalg, python-igraph gerekli)
- `SpectralClustering`: Spectral clustering (scikit-learn gerekli)
- `create_clustering_algorithm()`: Factory function
- EnhancedKG ve NetworkX graph formatlarÄ±nÄ± destekler
- Self-loop edge'leri otomatik filtreler

#### `drg/optimizer/`
DSPy optimizer desteÄŸi:
- `DRGOptimizer`: Optimizer wrapper class
- `ExtractionMetrics`: Evaluation metrics (precision, recall, F1)
- `BootstrapFewShot`, `MIPRO`, `COPRO`, `LabeledFewShot` desteÄŸi

---

## Declarative YapÄ±

### Declarative YaklaÅŸÄ±mÄ±n AvantajlarÄ±

1. **Basitlik**: KullanÄ±cÄ± sadece "ne" istediÄŸini tanÄ±mlar
2. **Esneklik**: Sistem otomatik olarak en iyi yÃ¶ntemi seÃ§er
3. **BakÄ±m KolaylÄ±ÄŸÄ±**: Implementation detaylarÄ± gizlenir
4. **Test Edilebilirlik**: Schema'lar kolayca test edilebilir

### DRG'de Declarative YapÄ±

#### 1. Schema TanÄ±mlama

```python
# Basit schema
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)

# GeliÅŸmiÅŸ schema (description'lar ile)
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[
        Relation(
            "produces", 
            "Company", 
            "Product",
            description="Bu iliÅŸki, bir ÅŸirketin belirli bir Ã¼rÃ¼nÃ¼ Ã¼rettiÄŸini, geliÅŸtirdiÄŸini veya piyasaya sÃ¼rdÃ¼ÄŸÃ¼nÃ¼ gÃ¶sterir. ÃœrÃ¼n, ÅŸirketin ana faaliyet alanÄ± veya Ã¼retim hattÄ±nÄ±n bir parÃ§asÄ± olabilir."
        )
    ]
)
```

#### 2. JSON Schema FormatÄ±

Schema'lar JSON formatÄ±nda da tanÄ±mlanabilir:

```json
{
  "entities": [
    {
      "name": "Company",
      "description": "Business organizations and corporations"
    },
    {
      "name": "Product",
      "description": "Products, devices, goods"
    }
  ],
  "relations": [
    {
      "name": "produces",
      "source": "Company",
      "target": "Product",
      "description": "Bu iliÅŸki, bir ÅŸirketin belirli bir Ã¼rÃ¼nÃ¼ Ã¼rettiÄŸini gÃ¶sterir..."
    }
  ]
}
```

#### 3. Otomatik Extraction

Schema tanÄ±mlandÄ±ktan sonra, extraction otomatik olarak yapÄ±lÄ±r:

```python
# Sadece schema ve metin yeterli
text = "Apple produces iPhone, iPad, and Mac computers."
entities, triples = extract_typed(text, schema)

# Sistem otomatik olarak:
# 1. LLM'i konfigÃ¼re eder
# 2. Entity extraction yapar
# 3. Relation extraction yapar
# 4. SonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r
```

### Declarative vs Imperative KarÅŸÄ±laÅŸtÄ±rma

**Imperative YaklaÅŸÄ±m** (Geleneksel):
```python
# AdÄ±m adÄ±m manuel iÅŸlem
text = "Apple produces iPhone"
# 1. Metni tokenize et
tokens = tokenize(text)
# 2. NER (Named Entity Recognition) Ã§alÄ±ÅŸtÄ±r
entities = ner_model.predict(tokens)
# 3. Relation extraction Ã§alÄ±ÅŸtÄ±r
relations = relation_model.predict(tokens, entities)
# 4. KG oluÅŸtur
kg = build_kg(entities, relations)
```

**Declarative YaklaÅŸÄ±m** (DRG):
```python
# Sadece ne istediÄŸinizi tanÄ±mlayÄ±n
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)
# Sistem otomatik olarak halleder
entities, triples = extract_typed(text, schema)
kg = EnhancedKG.from_typed(entities, triples)
```

---

## Pipeline Mimarisi

### Tam GraphRAG Pipeline

DRG'nin tam pipeline'Ä± ÅŸu adÄ±mlardan oluÅŸur:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1. CHUNKING                              â”‚
â”‚  Metin â†’ Token/Sentence-based Chunking â†’ Chunks            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              2. KNOWLEDGE GRAPH EXTRACTION                  â”‚
â”‚  Chunks â†’ DSPy Extraction â†’ Entities + Relations            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             3. ENHANCED KG OLUÅTURMA                        â”‚
â”‚  Entities + Relations â†’ KGNode + KGEdge â†’ EnhancedKG       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           4. ENTITY EMBEDDING'LERÄ° EKLEME                    â”‚
â”‚  EnhancedKG â†’ Embedding Provider â†’ Node Embeddings         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        5. CLUSTERING VE COMMUNITY REPORTS                   â”‚
â”‚  EnhancedKG â†’ Clustering Algorithm â†’ Clusters             â”‚
â”‚  Clusters â†’ Community Report Generator â†’ Reports           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              6. GRAPHRAG RETRIEVAL                          â”‚
â”‚  Query â†’ Seed Entity Finding â†’ Graph Traversal             â”‚
â”‚  Graph Traversal + Community Reports â†’ Context            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AdÄ±m AdÄ±m AÃ§Ä±klama

#### 1. Chunking (ParÃ§alama)

**AmaÃ§**: Uzun metinleri iÅŸlenebilir parÃ§alara bÃ¶lmek

**Stratejiler**:
- **Token-based**: Token sayÄ±sÄ±na gÃ¶re (Ã¶rn: 200 token)
- **Sentence-based**: CÃ¼mle sÄ±nÄ±rlarÄ±na gÃ¶re
- **Semantic**: Anlamsal benzerliÄŸe gÃ¶re

**Ã–rnek**:
```python
chunker = create_chunker(
    strategy="token_based",
    chunk_size=200,
    overlap_ratio=0.15
)
chunks = chunker.chunk(
    text=text,
    origin_dataset="apple_corpus",
    origin_file="apple_history.txt"
)
```

**Ã‡Ä±ktÄ±**: Chunk listesi (her chunk: text, token_count, chunk_id, metadata)

#### 2. Knowledge Graph Extraction

**AmaÃ§**: Chunk'lardan entity ve relation Ã§Ä±karmak

**YÃ¶ntem**: DSPy framework kullanarak LLM ile extraction

**SÃ¼reÃ§**:
1. Schema'dan dinamik DSPy signature'larÄ± oluÅŸturulur
2. **Chunk-based Processing**: Her chunk Ã¼zerinde baÄŸÄ±msÄ±z extraction yapÄ±lÄ±r
   - Her chunk iÃ§in entity extraction
   - Her chunk iÃ§in relation extraction (entity'ler context olarak verilir)
3. SonuÃ§lar birleÅŸtirilir (duplicate entity ve relation'lar otomatik filtrelenir)
4. Self-loop edge'ler filtrelenir (source == target olan edge'ler atlanÄ±r)

**Ã–rnek**:
```python
extractor = KGExtractor(schema)
all_entities = set()
all_triples = set()

for chunk in chunks:
    result = extractor.forward(chunk.text)
    entities = json.loads(result.entities)  # [[name, type], ...]
    relations = json.loads(result.relations)  # [[source, relation, target], ...]
    
    # Unique entity ve relation'larÄ± topla
    all_entities.update([(e[0], e[1]) for e in entities])
    all_triples.update([(r[0], r[1], r[2]) for r in relations])
```

**Ã‡Ä±ktÄ±**: Unique entity listesi ve relation listesi (triples)

#### 3. Enhanced KG OluÅŸturma

**AmaÃ§**: Entity ve relation'lardan EnhancedKG yapÄ±sÄ± oluÅŸturmak

**YapÄ±**:
- **KGNode**: id, type, properties, metadata, embedding
- **KGEdge**: source, target, relationship_type, relationship_detail, metadata

**Ã–rnek**:
```python
enhanced_kg = EnhancedKG()

# Node'lar ekle
for entity_name, entity_type in entities_list:
    node = KGNode(id=entity_name, type=entity_type)
    enhanced_kg.add_node(node)

# Edge'ler ekle
for source, relation, target in triples_list:
    edge = KGEdge(
        source=source,
        target=target,
        relationship_type=relation,
        relationship_detail=relation_descriptions.get(relation, f"{source} {relation} {target}"),
        metadata={}
    )
    enhanced_kg.add_edge(edge)
```

**Ã‡Ä±ktÄ±**: EnhancedKG objesi (nodes, edges, clusters)

#### 4. Entity Embedding'leri Ekleme

**AmaÃ§**: Node'lara embedding vektÃ¶rleri eklemek (GraphRAG iÃ§in gerekli)

**Provider'lar**:
- OpenAI (text-embedding-3-small, text-embedding-3-large)
- Gemini (text-embedding-004)
- OpenRouter (Ã§eÅŸitli modeller)
- Local (sentence-transformers)

**Ã–rnek**:
```python
embedding_provider = create_embedding_provider(
    provider="openrouter",
    model="openrouter/text-embedding-ada-002"
)
entity_texts = {node_id: node_id for node_id in enhanced_kg.nodes.keys()}
enhanced_kg.add_entity_embeddings(embedding_provider, entity_texts)
```

**Ã‡Ä±ktÄ±**: EnhancedKG (her node'da embedding vektÃ¶rÃ¼)

#### 5. Clustering ve Community Reports

**AmaÃ§**: Graph'u cluster'lara bÃ¶lmek ve her cluster iÃ§in Ã¶zet rapor oluÅŸturmak

**Clustering AlgoritmalarÄ±**:
- **Louvain**: Community detection (python-louvain paketi gerekli)
- **Leiden**: Louvain'in geliÅŸtirilmiÅŸ versiyonu (leidenalg, python-igraph gerekli)
- **Spectral**: Spectral clustering (scikit-learn gerekli)

**SÃ¼reÃ§**:
1. EnhancedKG NetworkX graph formatÄ±na Ã§evrilir
2. SeÃ§ilen algoritma ile clustering yapÄ±lÄ±r
3. Cluster'lar EnhancedKG'ye eklenir
4. Her cluster iÃ§in community report oluÅŸturulur

**Community Reports Ä°Ã§eriÄŸi**:
- **Top Actors**: Cluster'daki Ã¶nemli entity'ler (entity frequency'e gÃ¶re)
- **Top Relationships**: Cluster'daki Ã¶nemli iliÅŸkiler (relationship frequency'e gÃ¶re)
- **Themes**: Cluster'Ä±n temalarÄ± (top actors ve relationships'ten Ã§Ä±karÄ±lÄ±r)
- **Summary**: Cluster Ã¶zeti

**Ã–rnek**:
```python
clustering_algorithm = create_clustering_algorithm(algorithm="louvain")
G = nx.Graph()

# EnhancedKG'yi NetworkX'e Ã§evir
for node_id in enhanced_kg.nodes.keys():
    G.add_node(node_id)
for edge in enhanced_kg.edges:
    G.add_edge(edge.source, edge.target)

# Clustering yap
clusters = clustering_algorithm.cluster(G)

# Cluster'larÄ± EnhancedKG'ye ekle
for cluster in clusters:
    kg_cluster = Cluster(
        id=f"cluster_{cluster.cluster_id}",
        node_ids=set(cluster.nodes),
        metadata=cluster.metadata
    )
    enhanced_kg.add_cluster(kg_cluster)

# Community reports oluÅŸtur
report_generator = CommunityReportGenerator(enhanced_kg)
reports = report_generator.generate_all_reports()
```

**Ã‡Ä±ktÄ±**: Cluster listesi ve Community report listesi

#### 6. GraphRAG Retrieval

**AmaÃ§**: Query'ye gÃ¶re KG'den ilgili bilgileri retrieve etmek

**SÃ¼reÃ§**:
1. **Seed Entity Finding**: Query'yi embed et, KG'deki node embedding'leri ile karÅŸÄ±laÅŸtÄ±r, en benzer node'larÄ± bul
2. **Graph Traversal**: Seed entity'lerden baÅŸlayarak graph'Ä± traverse et
3. **Subgraph Extraction**: Ä°lgili node ve edge'leri iÃ§eren subgraph oluÅŸtur
4. **Community Report Integration**: Ä°lgili cluster'larÄ±n community report'larÄ±nÄ± ekle
5. **Context Assembly**: TÃ¼m bilgileri context olarak birleÅŸtir

**Ã–rnek**:
```python
retriever = create_graphrag_retriever(
    kg=enhanced_kg,
    embedding_provider=embedding_provider
)
context = retriever.retrieve(
    query="What products does Apple produce?",
    max_hops=2,
    top_k=5
)
```

**Ã‡Ä±ktÄ±**: RetrievalContext (entities, relationships, community_reports, chunks)

### Pipeline Ã‡Ä±ktÄ±larÄ±

Pipeline Ã§alÄ±ÅŸtÄ±ktan sonra ÅŸu dosyalar oluÅŸturulur:

- `outputs/{example_name}_schema.json`: KullanÄ±lan schema (Enhanced veya Legacy format)
- `outputs/{example_name}_kg.json`: OluÅŸturulan Knowledge Graph (EnhancedKG formatÄ±nda)
- `outputs/{example_name}_community_reports.json`: Community report'lar (clustering yapÄ±ldÄ±ysa)
- `outputs/{example_name}_summary.json`: Pipeline Ã¶zeti (chunk sayÄ±sÄ±, node sayÄ±sÄ±, cluster sayÄ±sÄ±, vb.)

**Not**: Dosya isimlendirme formatÄ± sayÄ± baÅŸta kullanÄ±lÄ±r (Ã¶rn: `1example`, `2example`, `3example`). Pipeline hem eski format (`example1`) hem de yeni format (`1example`) destekler.

---

## BileÅŸenler ve Metodlar

### Schema BileÅŸenleri

#### Entity ve Relation TanÄ±mlarÄ±

```python
# Basit Entity
entity = Entity("Company")

# Basit Relation
relation = Relation(
    name="produces",
    source="Company",
    target="Product",
    description="Åirket Ã¼rÃ¼n Ã¼retir"  # Opsiyonel aÃ§Ä±klayÄ±cÄ± cÃ¼mle
)

# DRGSchema
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)
```

#### Enhanced Schema BileÅŸenleri

```python
# EntityType (geliÅŸmiÅŸ entity tanÄ±mÄ±)
entity_type = EntityType(
    name="Company",
    description="Business organizations and corporations",
    examples=["Apple", "Google", "Microsoft"],
    properties={"industry": "tech"}
)

# RelationGroup (iliÅŸkili relation'larÄ± gruplama)
relation_group = RelationGroup(
    name="production",
    description="How companies create products",
    relations=[
        Relation(
            name="produces",
            src="Company",
            dst="Product",
            description="Relationship type explanation - why this relationship exists",
            detail="Specific detail about why/how entities are connected"
        ),
        Relation(
            name="manufactures",
            src="Company",
            dst="Product",
            description="Manufacturing relationship",
            detail="Companies create products through manufacturing processes"
        )
    ],
    examples=[]  # Opsiyonel: Ã–rnek metinler ve entity/relation'lar
)

# EnhancedDRGSchema
enhanced_schema = EnhancedDRGSchema(
    entity_types=[entity_type],
    relation_groups=[relation_group],
    auto_discovery=True  # Schema'da tanÄ±mlÄ± olmayan relation'larÄ± da bul
)
```

### Extraction MetodlarÄ±

#### `extract_typed(text, schema)`

Metinden typed entity ve relation Ã§Ä±karÄ±r.

**Parametreler**:
- `text` (str): Ä°ÅŸlenecek metin
- `schema` (DRGSchema | EnhancedDRGSchema): Åema tanÄ±mÄ±

**DÃ¶ndÃ¼rÃ¼r**:
- `Tuple[List[Tuple[str, str]], List[Tuple[str, str, str]]]`: (entities, triples)
  - entities: `[(entity_name, entity_type), ...]`
  - triples: `[(source, relation, target), ...]`

**Ã–rnek**:
```python
text = "Apple produces iPhone. Tim Cook is the CEO of Apple."
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product"), Entity("Person")],
    relations=[
        Relation("produces", "Company", "Product"),
        Relation("ceo_of", "Person", "Company")
    ]
)

entities, triples = extract_typed(text, schema)
# entities: [("Apple", "Company"), ("iPhone", "Product"), ("Tim Cook", "Person")]
# triples: [("Apple", "produces", "iPhone"), ("Tim Cook", "ceo_of", "Apple")]
```

#### `KGExtractor`

DSPy module olarak extraction yapar.

**KullanÄ±m**:
```python
extractor = KGExtractor(schema)
result = extractor.forward(text)
entities = json.loads(result.entities)
relations = json.loads(result.relations)
```

**Ã–zellikler**:
- Rate limit handling (otomatik retry)
- Exponential backoff
- JSON string parsing (Gemini uyumluluÄŸu iÃ§in)

### Chunking MetodlarÄ±

#### `create_chunker(strategy, chunk_size, overlap_ratio, preset)`

Chunker oluÅŸturur.

**Parametreler**:
- `strategy` (str): "token_based" | "sentence_based" | "semantic"
- `chunk_size` (int): Chunk boyutu (token veya cÃ¼mle sayÄ±sÄ±)
- `overlap_ratio` (float): Chunk'lar arasÄ± overlap oranÄ± (0.0-1.0)
- `preset` (str): Preset ismi (Ã¶rn: "graphrag") - preset belirtilirse diÄŸer parametreler override edilir

**Preset'ler**:
- `"graphrag"`: GraphRAG iÃ§in optimize edilmiÅŸ chunking (token_based, chunk_size=200, overlap_ratio=0.15)
- `"medium"`: Orta boyutlu chunk'lar iÃ§in (token_based, chunk_size=500, overlap_ratio=0.1)

**Ã–rnek**:
```python
# Preset kullanarak
chunker = create_chunker(preset="graphrag")
chunks = chunker.chunk(text, origin_dataset="corpus", origin_file="file.txt")

# Manuel parametrelerle
chunker = create_chunker(
    strategy="token_based",
    chunk_size=200,
    overlap_ratio=0.15
)
chunks = chunker.chunk(text, origin_dataset="corpus", origin_file="file.txt")
```

### Embedding MetodlarÄ±

#### `create_embedding_provider(provider, model, **kwargs)`

Embedding provider oluÅŸturur.

**Parametreler**:
- `provider` (str): "openai" | "gemini" | "openrouter" | "local"
- `model` (str): Model adÄ± (Ã¶rn: "text-embedding-3-small")
- `**kwargs`: Provider-specific parametreler

**Ã–rnek**:
```python
# OpenAI
provider = create_embedding_provider(
    provider="openai",
    model="text-embedding-3-small"
)

# OpenRouter
provider = create_embedding_provider(
    provider="openrouter",
    model="openrouter/text-embedding-ada-002"
)

# Local
provider = create_embedding_provider(
    provider="local",
    model="sentence-transformers/all-MiniLM-L6-v2"
)

# Embedding yap
embedding = provider.embed("Apple")
embeddings = provider.embed_batch(["Apple", "iPhone"])
```

### Knowledge Graph MetodlarÄ±

#### `EnhancedKG`

Ana Knowledge Graph class'Ä±.

**Metodlar**:
- `add_node(node)`: Node ekle
- `add_edge(edge)`: Edge ekle
- `add_cluster(cluster)`: Cluster ekle
- `add_entity_embeddings(provider, entity_texts)`: Entity embedding'leri ekle
- `to_dict()`: Dictionary'ye Ã§evir
- `to_json()`: JSON string'e Ã§evir

**Ã–rnek**:
```python
kg = EnhancedKG()

# Node ekle
node = KGNode(id="Apple", type="Company", properties={}, metadata={})
kg.add_node(node)

# Edge ekle
edge = KGEdge(
    source="Apple",
    target="iPhone",
    relationship_type="produces",
    relationship_detail="Apple iPhone Ã¼retir",
    metadata={}
)
kg.add_edge(edge)

# Embedding ekle
provider = create_embedding_provider(provider="openai")
entity_texts = {"Apple": "Apple", "iPhone": "iPhone"}
kg.add_entity_embeddings(provider, entity_texts)
```

### Retrieval MetodlarÄ±

#### `create_graphrag_retriever(kg, embedding_provider)`

GraphRAG retriever oluÅŸturur.

**Parametreler**:
- `kg` (EnhancedKG): Knowledge Graph
- `embedding_provider` (EmbeddingProvider): Embedding provider

**Ã–rnek**:
```python
retriever = create_graphrag_retriever(
    kg=enhanced_kg,
    embedding_provider=embedding_provider
)

context = retriever.retrieve(
    query="What products does Apple produce?",
    max_hops=2,
    top_k=5
)

# Context iÃ§eriÄŸi:
# - entities: List of entities
# - relationships: List of relationships
# - community_reports: List of community reports
# - chunks: List of relevant chunks
```

### Clustering MetodlarÄ±

#### `create_clustering_algorithm(algorithm)`

Clustering algorithm oluÅŸturur.

**Parametreler**:
- `algorithm` (str): "louvain" | "leiden" | "spectral"

**Ã–rnek**:
```python
algorithm = create_clustering_algorithm(algorithm="louvain")
G = nx.Graph()  # NetworkX graph
# Graph'u doldur
clusters = algorithm.cluster(G)  # List of node sets
```

---

## DiÄŸer KG Sistemlerinden FarklarÄ±

### 1. Declarative vs Imperative

**Geleneksel KG Sistemleri**:
- Imperative yaklaÅŸÄ±m: AdÄ±m adÄ±m manuel iÅŸlem
- Kod yazma gereksinimi
- Implementation detaylarÄ±na hakim olma zorunluluÄŸu

**DRG**:
- Declarative yaklaÅŸÄ±m: Sadece schema tanÄ±mlama
- Minimal kod
- Implementation detaylarÄ± gizli

### 2. Dataset-Agnostic TasarÄ±m

**Geleneksel KG Sistemleri**:
- Genellikle belirli bir domain iÃ§in optimize edilmiÅŸ
- Domain-specific adaptasyon gerektirir

**DRG**:
- Herhangi bir veri kaynaÄŸÄ±ndan baÄŸÄ±msÄ±z
- Pluggable components ile kolay adaptasyon
- Domain-specific optimizasyonlar core pipeline'Ä± deÄŸiÅŸtirmeden eklenebilir

### 3. GraphRAG DesteÄŸi

**Geleneksel KG Sistemleri**:
- Genellikle sadece KG oluÅŸturma
- Retrieval iÃ§in ayrÄ± sistemler gerekir

**DRG**:
- KG oluÅŸturma + GraphRAG retrieval
- End-to-end pipeline
- Community reports ile zengin context

### 4. LLM Entegrasyonu

**Geleneksel KG Sistemleri**:
- Genellikle rule-based veya ML-based extraction
- LLM entegrasyonu manuel

**DRG**:
- DSPy framework ile native LLM entegrasyonu
- Otomatik LLM konfigÃ¼rasyonu
- Multi-provider desteÄŸi (OpenAI, Gemini, Anthropic, vb.)

### 5. Relationship Description DesteÄŸi

**Geleneksel KG Sistemleri**:
- Genellikle sadece relation type (Ã¶rn: "produces")
- AÃ§Ä±klayÄ±cÄ± cÃ¼mleler yok

**DRG**:
- Relation description desteÄŸi
- Her relation iÃ§in aÃ§Ä±klayÄ±cÄ± cÃ¼mle
- Daha zengin semantic bilgi

### 6. Monolithic-Modular Mimarisi

**Geleneksel KG Sistemleri**:
- Genellikle tamamen modÃ¼ler (ayrÄ± paketler)
- Veya tamamen monolithic (tek blok)

**DRG**:
- Monolithic-modular hybrid
- Tek deployment unit
- ModÃ¼ler test edilebilirlik

### 7. Enhanced Schema

**Geleneksel KG Sistemleri**:
- Genellikle basit entity-relation tanÄ±mlarÄ±
- Gruplama ve property desteÄŸi sÄ±nÄ±rlÄ±

**DRG**:
- Enhanced schema (EntityType, RelationGroup, EntityGroup, PropertyGroup)
- Zengin metadata desteÄŸi
- Auto-discovery Ã¶zelliÄŸi

---

## KullanÄ±m Ã–rnekleri

### Basit KullanÄ±m

```python
from drg import Entity, Relation, DRGSchema, extract_typed, EnhancedKG, KGNode, KGEdge

# Schema tanÄ±mla
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)

# Metinden Ã§Ä±karÄ±m yap
text = "Apple produces iPhone, iPad, and Mac computers."
entities, triples = extract_typed(text, schema)

# EnhancedKG oluÅŸtur
kg = EnhancedKG()
for entity_name, entity_type in entities:
    kg.add_node(KGNode(id=entity_name, type=entity_type))

for source, relation, target in triples:
    kg.add_edge(KGEdge(
        source=source,
        target=target,
        relationship_type=relation,
        relationship_detail=f"{source} {relation} {target}",
        metadata={}
    ))

# JSON'a Ã§evir
print(kg.to_json(indent=2))
```

### Tam GraphRAG Pipeline

```python
from drg.chunking import create_chunker
from drg.embedding import create_embedding_provider
from drg.extract import KGExtractor, _configure_llm_auto
from drg.schema import DRGSchema, Entity, Relation
from drg.graph.kg_core import EnhancedKG, KGNode, KGEdge
from drg.retrieval import create_graphrag_retriever

# 1. Chunking
chunker = create_chunker(strategy="token_based", chunk_size=200)
chunks = chunker.chunk(text, origin_dataset="corpus", origin_file="file.txt")

# 2. LLM konfigÃ¼rasyonu
_configure_llm_auto()

# 3. KG Extraction
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)
extractor = KGExtractor(schema)
result = extractor.forward(text)
entities = json.loads(result.entities)
triples = json.loads(result.relations)

# 4. EnhancedKG oluÅŸtur
kg = EnhancedKG()
# ... node ve edge ekleme

# 5. Embedding ekle
provider = create_embedding_provider(provider="openai")
kg.add_entity_embeddings(provider, entity_texts)

# 6. GraphRAG Retrieval
retriever = create_graphrag_retriever(kg=kg, embedding_provider=provider)
context = retriever.retrieve(query="What products does Apple produce?")
```

### JSON Schema ile KullanÄ±m

```python
import json
from drg.schema import DRGSchema, Entity, Relation

# Schema'yÄ± JSON'dan yÃ¼kle
with open("schema.json", "r") as f:
    schema_data = json.load(f)

entities = [Entity(e["name"]) for e in schema_data["entities"]]
relations = [
    Relation(
        r["name"],
        r["source"],
        r["target"],
        description=r.get("description", "")
    )
    for r in schema_data["relations"]
]

schema = DRGSchema(entities=entities, relations=relations)
```

### Pipeline Example KullanÄ±mÄ±

```bash
# Pipeline'Ä± Ã§alÄ±ÅŸtÄ±r (sayÄ± baÅŸta format)
python examples/graphrag_pipeline_example.py 1
python examples/graphrag_pipeline_example.py 1example
python examples/graphrag_pipeline_example.py example1  # Otomatik 1example'a Ã§evrilir

# Ã‡Ä±ktÄ±lar:
# - outputs/1example_schema.json
# - outputs/1example_kg.json
# - outputs/1example_community_reports.json (clustering yapÄ±ldÄ±ysa)
# - outputs/1example_summary.json
```

### Otomatik Schema Generation

Metin verildiÄŸinde, schema yoksa otomatik olarak EnhancedDRGSchema oluÅŸturulur:

```python
from drg.extract import generate_schema_from_text

# Metinden otomatik schema oluÅŸtur
text = "Apple Inc. is a technology company..."
schema = generate_schema_from_text(text)

# Schema iÃ§eriÄŸi:
# - entity_types: Properties ve examples ile zengin entity tanÄ±mlarÄ±
# - relation_groups: Semantic olarak gruplandÄ±rÄ±lmÄ±ÅŸ relation'lar
# - Her relation iÃ§in description (baÄŸlantÄ± sebebi) ve detail (baÄŸlantÄ± detayÄ±)
```

### Web API ve Visualization

DRG, FastAPI tabanlÄ± bir web server ve interaktif graph visualization UI sunar:

#### API Server BaÅŸlatma

```python
from drg.api import DRGAPIServer
from drg.graph import EnhancedKG

# KG'yi yÃ¼kle
kg = EnhancedKG.from_json_file("outputs/4example_kg.json")

# API server oluÅŸtur ve baÅŸlat
server = DRGAPIServer(kg=kg)
server.run(host="0.0.0.0", port=8000)
```

Veya script ile:

```bash
# En son gÃ¼ncellenen KG ile otomatik baÅŸlat
python examples/api_server_example.py

# Belirli bir example ile baÅŸlat
python examples/api_server_example.py 4example

# Shell script ile (GEMINI_API_KEY otomatik export edilir)
./start_api_server.sh 4example
```

#### API Endpoints

- `GET /` - Web UI (interaktif graph visualization)
- `GET /api/graph` - Full graph data (JSON)
- `GET /api/graph/stats` - Graph statistics
- `GET /api/communities` - All community/cluster data
- `GET /api/visualization/{format}` - Visualization data (cytoscape, vis-network, d3)
- `POST /api/query` - Execute query ve provenance chain al
- `GET /api/provenance/{provenance_id}` - Query provenance chain
- `POST /api/neo4j/sync` - Neo4j'e sync
- `GET /api/neo4j/stats` - Neo4j statistics

#### Web UI Ã–zellikleri

- **Interactive Graph**: Cytoscape.js ile zoom, pan, drag
- **Community Coloring**: Cluster'lara gÃ¶re node renklendirme
- **Node/Edge Details**: Hover ile detay bilgileri
- **Multiple Layouts**: breadthfirst, concentric, cose, grid, circle
- **Query Interface**: Query girme ve sonuÃ§ gÃ¶rÃ¼ntÃ¼leme
- **Provenance Visualization**: Query sonuÃ§larÄ±nÄ±n provenance chain'i

#### Neo4j Integration

```python
from drg.graph import Neo4jConfig, Neo4jExporter

# Neo4j konfigÃ¼rasyonu
config = Neo4jConfig(
    uri="bolt://localhost:7687",
    user="neo4j",
    password="password"
)

# Exporter oluÅŸtur ve sync et
exporter = Neo4jExporter(config)
exporter.sync_kg(enhanced_kg, clear_existing=True)

# Graph statistics
stats = exporter.get_graph_stats()
print(f"Nodes: {stats['nodes']}, Edges: {stats['edges']}")
```

---

## GeliÅŸtirme ve KatkÄ±da Bulunma

### GeliÅŸtirme OrtamÄ± Kurulumu

```bash
# Projeyi klonla
git clone <repository-url>
cd DRG

# Virtual environment oluÅŸtur
python -m venv venv
source venv/bin/activate  # macOS/Linux
# veya
venv\Scripts\activate  # Windows

# Projeyi kur
pip install -e .

# Dependencies kur
pip install -r requirements.txt
```

### Test Ã‡alÄ±ÅŸtÄ±rma

```bash
# TÃ¼m testler
pytest tests/

# Belirli bir test
pytest tests/test_basic.py::test_extract_entities_and_relations_with_openai

# API key olmadan yapÄ± testleri
python examples/graphrag_pipeline_example.py example1
```

### Kod StandartlarÄ±

- **Type Hints**: TÃ¼m fonksiyonlar type hint'li
- **Docstrings**: Google style docstrings
- **Linting**: ruff, mypy, black
- **Interface-First**: Ã–nce interface, sonra implementation

### Yeni BileÅŸen Ekleme

1. Interface tanÄ±mla (`drg/<module>/interface.py`)
2. Implementation yap (`drg/<module>/<provider>.py`)
3. Factory function ekle (`drg/<module>/__init__.py`)
4. Test yaz (`tests/test_<module>.py`)
5. DokÃ¼mantasyon gÃ¼ncelle (`docs/<module>.md`)

---

## SonuÃ§

DRG, modern LLM teknolojilerini kullanarak declarative bir yaklaÅŸÄ±mla Knowledge Graph oluÅŸturma ve GraphRAG retrieval yapma imkanÄ± sunan, dataset-agnostic bir Python kÃ¼tÃ¼phanesidir. Proje, research-grade kalitede, community publication-ready bir yapÄ±da tasarlanmÄ±ÅŸtÄ±r.

### Projenin GÃ¼Ã§lÃ¼ YÃ¶nleri

1. âœ… **Declarative YaklaÅŸÄ±m**: Minimal kod, maksimum esneklik
2. âœ… **Dataset-Agnostic**: Herhangi bir veri kaynaÄŸÄ±ndan baÄŸÄ±msÄ±z
3. âœ… **GraphRAG DesteÄŸi**: End-to-end GraphRAG pipeline
4. âœ… **Multi-Provider**: OpenAI, Gemini, Anthropic, OpenRouter, vb.
5. âœ… **Enhanced Schema**: Zengin metadata ve aÃ§Ä±klama desteÄŸi
6. âœ… **Modular Architecture**: Kolay test edilebilirlik ve geniÅŸletilebilirlik

### Gelecek GeliÅŸtirmeler

- [ ] Neo4j, ArangoDB gibi graph database desteÄŸi
- [ ] Daha fazla clustering algoritmasÄ±
- [ ] Real-time KG update mekanizmasÄ±
- [ ] Web UI
- [ ] Docker containerization
- [ ] Cloud deployment (AWS, GCP, Azure)

---

**Not**: Bu dokÃ¼mantasyon, DRG projesinin mevcut durumunu (v0.1.0a0) yansÄ±tmaktadÄ±r. API deÄŸiÅŸiklikleri olabilir.

