# DRG Projesi: KapsamlÄ± Proje DokÃ¼mantasyonu

## ğŸ“‹ Ä°Ã§indekiler

1. [Proje Genel BakÄ±ÅŸ](#proje-genel-bakÄ±ÅŸ)
2. [Temel Kavramlar](#temel-kavramlar)
3. [Proje Felsefesi ve TasarÄ±m Prensipleri](#proje-felsefesi-ve-tasarÄ±m-prensipleri)
4. [Proje YapÄ±sÄ±](#proje-yapÄ±sÄ±)
5. [Declarative YapÄ±](#declarative-yapÄ±)
6. [Pipeline Mimarisi](#pipeline-mimarisi)
7. [BileÅŸenler ve Metodlar](#bileÅŸenler-ve-metodlar)
8. [DiÄŸer KG Sistemlerinden FarklarÄ±](#diÄŸer-kg-sistemlerinden-farklarÄ±)
9. [KullanÄ±m Ã–rnekleri](#kullanÄ±m-Ã¶rnekleri)
10. [GeliÅŸtirme ve KatkÄ±da Bulunma](#geliÅŸtirme-ve-katkÄ±da-bulunma)

---

## Proje Genel BakÄ±ÅŸ

### DRG Nedir?

**DRG (Declarative Relationship Generation)**, metinlerden bilgi grafiÄŸi (Knowledge Graph) Ã§Ä±karÄ±mÄ± yapmak iÃ§in tasarlanmÄ±ÅŸ, dataset-agnostic (veri kaynaÄŸÄ±ndan baÄŸÄ±msÄ±z) bir Python kÃ¼tÃ¼phanesidir. DRG, modern Large Language Model (LLM) teknolojilerini kullanarak, sadece ÅŸema tanÄ±mlayarak otomatik olarak entity (varlÄ±k) ve relation (iliÅŸki) Ã§Ä±karÄ±mÄ± yapar.

### Projenin Temel AmacÄ±

DRG projesi, aÅŸaÄŸÄ±daki temel amaÃ§lara hizmet eder:

1. **Declarative (Deklaratif) YaklaÅŸÄ±m**: KullanÄ±cÄ±lar "ne" istediklerini tanÄ±mlar, sistem "nasÄ±l" yapÄ±lacaÄŸÄ±nÄ± otomatik olarak halleder.

2. **Dataset-Agnostic TasarÄ±m**: Herhangi bir veri kaynaÄŸÄ±ndan (metin, PDF, JSON, vb.) baÄŸÄ±msÄ±z olarak Ã§alÄ±ÅŸÄ±r.

3. **GraphRAG DesteÄŸi**: Sadece klasik RAG (Retrieval-Augmented Generation) deÄŸil, aynÄ± zamanda GraphRAG (Graph-based RAG) yapÄ±sÄ±nÄ± da destekler.

4. **Research-Grade Kalite**: Akademik araÅŸtÄ±rmalar ve yayÄ±nlar iÃ§in uygun, yÃ¼ksek kaliteli kod yapÄ±sÄ±.

5. **Community Publication-Ready**: Topluluk tarafÄ±ndan kullanÄ±lmaya ve yayÄ±nlanmaya hazÄ±r bir sistem.

### Projenin Ã–zellikleri

- âœ… **Declarative Schema**: Sadece entity tipleri ve iliÅŸkileri tanÄ±mlayÄ±n, gerisini DRG halletsin
- âœ… **Otomatik Schema Generation**: Metinden otomatik olarak EnhancedDRGSchema oluÅŸturma (`generate_schema_from_text`)
- âœ… **DSPy Entegrasyonu**: Modern LLM'lerle Ã§alÄ±ÅŸan gÃ¼Ã§lÃ¼ extraction pipeline
- âœ… **Enhanced Schema**: EntityType (properties, examples), RelationGroup (semantic grouping), Relation (description, detail) ile zengin ÅŸema tanÄ±mlarÄ±
- âœ… **Chunk-based KG Extraction**: Her chunk Ã¼zerinde baÄŸÄ±msÄ±z extraction, sonuÃ§larÄ±n birleÅŸtirilmesi
- âœ… **Otomatik LLM KonfigÃ¼rasyonu**: Environment variable'lardan otomatik model ve API key yÃ¶netimi
- âœ… **GraphRAG Pipeline**: Chunking â†’ KG Extraction â†’ Embedding â†’ Clustering â†’ Community Reports â†’ Retrieval
- âœ… **Clustering DesteÄŸi**: Louvain, Leiden, Spectral algoritmalarÄ± ile community detection
- âœ… **Community Reports**: Her cluster iÃ§in otomatik Ã¶zet raporlar (top actors, top relationships, themes)
- âœ… **Preset-based Chunking**: "graphrag" gibi preset'lerle kolay chunking konfigÃ¼rasyonu
- âœ… **Multi-Provider DesteÄŸi**: OpenAI, Gemini, Anthropic, OpenRouter, Perplexity, Ollama
- âœ… **MCP API**: Agent interface iÃ§in Model Context Protocol desteÄŸi
- âœ… **Optimizer DesteÄŸi**: DSPy optimizer'larÄ± ile iterative learning
- âœ… **Self-loop Filtering**: KG'de self-loop edge'lerin otomatik filtrelenmesi

---

## Temel Kavramlar

### Knowledge Graph (Bilgi GrafiÄŸi) Nedir?

**Knowledge Graph (KG)**, bilgileri yapÄ±landÄ±rÄ±lmÄ±ÅŸ bir ÅŸekilde temsil eden bir graf yapÄ±sÄ±dÄ±r. KG'de:

- **Node (DÃ¼ÄŸÃ¼m)**: Entity'ler (varlÄ±klar) - Ã¶rneÄŸin: "Apple", "Steve Jobs", "iPhone"
- **Edge (Kenar)**: Relation'lar (iliÅŸkiler) - Ã¶rneÄŸin: "Apple â†’ produces â†’ iPhone"

KG'ler, bilgileri iliÅŸkisel bir yapÄ±da sakladÄ±ÄŸÄ± iÃ§in, sadece metin aramasÄ±ndan daha gÃ¼Ã§lÃ¼ sorgulama ve Ã§Ä±karÄ±m yapÄ±lmasÄ±na olanak tanÄ±r.

### Entity (VarlÄ±k) Nedir?

**Entity**, metinde bahsedilen somut veya soyut kavramlardÄ±r. Ã–rneÄŸin:
- **KiÅŸiler**: "Steve Jobs", "Tim Cook"
- **Åirketler**: "Apple Inc.", "Google"
- **ÃœrÃ¼nler**: "iPhone", "iPad"
- **Lokasyonlar**: "Cupertino", "California"

### Relation (Ä°liÅŸki) Nedir?

**Relation**, iki entity arasÄ±ndaki baÄŸlantÄ±yÄ± temsil eder. Ã–rneÄŸin:
- "Apple â†’ produces â†’ iPhone" (Apple, iPhone Ã¼retir)
- "Steve Jobs â†’ founded_by â†’ Apple" (Steve Jobs, Apple'Ä± kurdu)
- "Tim Cook â†’ ceo_of â†’ Apple" (Tim Cook, Apple'Ä±n CEO'sudur)

### Chunking (ParÃ§alama) Nedir?

**Chunking**, uzun metinleri daha kÃ¼Ã§Ã¼k, iÅŸlenebilir parÃ§alara bÃ¶lme iÅŸlemidir. LLM'ler genellikle sÄ±nÄ±rlÄ± token kapasitesine sahip olduÄŸu iÃ§in, uzun metinler Ã¶nce chunk'lara bÃ¶lÃ¼nÃ¼r, sonra her chunk Ã¼zerinde iÅŸlem yapÄ±lÄ±r.

DRG'de chunking stratejileri:
- **Token-based**: Token sayÄ±sÄ±na gÃ¶re bÃ¶lme
- **Sentence-based**: CÃ¼mle sÄ±nÄ±rlarÄ±na gÃ¶re bÃ¶lme
- **Semantic**: Anlamsal benzerliÄŸe gÃ¶re bÃ¶lme

### Embedding (VektÃ¶rleÅŸtirme) Nedir?

**Embedding**, metinleri sayÄ±sal vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rme iÅŸlemidir. Bu vektÃ¶rler, metinlerin anlamsal benzerliÄŸini Ã¶lÃ§mek iÃ§in kullanÄ±lÄ±r. Ã–rneÄŸin, "Apple" ve "iPhone" kelimeleri birbirine yakÄ±n vektÃ¶rlerle temsil edilir.

### RAG (Retrieval-Augmented Generation) Nedir?

**RAG**, LLM'lerin bilgiyi gerÃ§ek zamanlÄ± olarak retrieve (getirme) edip kullanmasÄ±na olanak tanÄ±yan bir yaklaÅŸÄ±mdÄ±r. RAG'de:
1. Metinler chunk'lara bÃ¶lÃ¼nÃ¼r ve embed edilir
2. Query (sorgu) embed edilir
3. Query'ye en benzer chunk'lar bulunur (vector similarity)
4. Bu chunk'lar LLM'e context olarak verilir
5. LLM, bu context'i kullanarak cevap Ã¼retir

### GraphRAG Nedir?

**GraphRAG**, RAG'in geliÅŸmiÅŸ bir versiyonudur. GraphRAG'de:
1. Metinlerden Knowledge Graph oluÅŸturulur
2. Query'den seed entity'ler bulunur (embedding kullanarak)
3. Graph traversal (graf gezinme) ile ilgili entity'ler bulunur
4. Community reports (topluluk raporlarÄ±) oluÅŸturulur
5. Bu bilgiler LLM'e context olarak verilir

GraphRAG'Ä±n avantajlarÄ±:
- Multi-hop reasoning (Ã§ok adÄ±mlÄ± Ã§Ä±karÄ±m) yapabilir
- Entity relationships explicit olarak kullanÄ±lÄ±r
- Graph topology'den bilgi Ã§Ä±karÄ±lÄ±r

### Declarative (Deklaratif) Programlama Nedir?

**Declarative programming**, "ne" istediÄŸinizi tanÄ±mladÄ±ÄŸÄ±nÄ±z, sistemin "nasÄ±l" yapÄ±lacaÄŸÄ±nÄ± otomatik olarak hallettiÄŸi bir programlama paradigmasÄ±dÄ±r.

**Imperative (Emirsel) YaklaÅŸÄ±m** (Geleneksel):
```python
# NasÄ±l yapÄ±lacaÄŸÄ±nÄ± adÄ±m adÄ±m tanÄ±mlarsÄ±nÄ±z
text = "Apple produces iPhone"
# 1. Metni parse et
# 2. Entity'leri bul
# 3. Relation'larÄ± bul
# 4. KG oluÅŸtur
```

**Declarative (Deklaratif) YaklaÅŸÄ±m** (DRG):
```python
# Sadece ne istediÄŸinizi tanÄ±mlarsÄ±nÄ±z
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)
# Sistem otomatik olarak extraction yapar
entities, triples = extract_typed(text, schema)
```

---

## Proje Felsefesi ve TasarÄ±m Prensipleri

### 1. Monolithic-Modular Mimarisi

DRG, **monolithic-modular** bir mimari kullanÄ±r:

- **Monolithic**: TÃ¼m bileÅŸenler aynÄ± codebase iÃ§inde, tek bir deployment unit
- **Modular**: Her bileÅŸen baÄŸÄ±msÄ±z interface'ler Ã¼zerinden iletiÅŸim kurar
- **Loose Coupling**: BileÅŸenler arasÄ± baÄŸÄ±mlÄ±lÄ±klar minimal ve aÃ§Ä±kÃ§a tanÄ±mlÄ±dÄ±r
- **High Cohesion**: Ä°lgili fonksiyonellik aynÄ± modÃ¼lde gruplanÄ±r

Bu yaklaÅŸÄ±mÄ±n avantajlarÄ±:
- Kolay deployment (tek bir paket)
- ModÃ¼ler test edilebilirlik
- Esnek bileÅŸen deÄŸiÅŸimi

### 2. Dataset-Agnostic TasarÄ±m

DRG, herhangi bir veri kaynaÄŸÄ±ndan baÄŸÄ±msÄ±z olarak Ã§alÄ±ÅŸÄ±r:

- **Abstraction Layers**: Veri kaynaÄŸÄ±, chunking stratejisi ve embedding modeli arasÄ±nda net arayÃ¼zler
- **Pluggable Components**: Her bileÅŸen baÄŸÄ±msÄ±z olarak deÄŸiÅŸtirilebilir ve test edilebilir
- **Metadata Preservation**: Her chunk, orijin veri kaynaÄŸÄ± ve iÅŸlem geÃ§miÅŸi hakkÄ±nda zengin metadata taÅŸÄ±r
- **Domain Adaptation**: Domain-specific optimizasyonlar, core pipeline'Ä± deÄŸiÅŸtirmeden eklenebilir

### 3. Interface-First Design

Her bileÅŸen iÃ§in Ã¶nce interface tanÄ±mlanÄ±r, sonra implementation yapÄ±lÄ±r:

```python
# Interface
class EmbeddingProvider(ABC):
    @abstractmethod
    def embed(self, text: str) -> List[float]:
        pass

# Implementation
class OpenAIEmbeddingProvider(EmbeddingProvider):
    def embed(self, text: str) -> List[float]:
        # Implementation
        pass
```

### 4. Dependency Injection

Hard dependencies yerine dependency injection kullanÄ±lÄ±r:

```python
# Bad
class Chunker:
    def __init__(self):
        self.tokenizer = TiktokenTokenizer()  # Hard dependency

# Good
class Chunker:
    def __init__(self, tokenizer: Tokenizer):
        self.tokenizer = tokenizer  # Injected dependency
```

---

## Proje YapÄ±sÄ±

### KlasÃ¶r YapÄ±sÄ±

```
DRG/
â”œâ”€â”€ drg/                    # Ana modÃ¼l (monolithic codebase)
â”‚   â”œâ”€â”€ __init__.py         # Public API exports
â”‚   â”œâ”€â”€ schema.py           # Schema tanÄ±mlarÄ± (Entity, Relation, DRGSchema)
â”‚   â”œâ”€â”€ extract.py          # DSPy extraction logic (KGExtractor)
â”‚   â”œâ”€â”€ graph.py            # Legacy KG class (backward compatibility)
â”‚   â”œâ”€â”€ cli.py              # CLI interface
â”‚   â”‚
â”‚   â”œâ”€â”€ chunking/           # Chunking layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ strategies.py   # Chunking strategies (token, sentence, semantic)
â”‚   â”‚   â””â”€â”€ validators.py   # Chunk validation
â”‚   â”‚
â”‚   â”œâ”€â”€ embedding/          # Embedding abstraction layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ providers.py    # Embedding provider interfaces
â”‚   â”‚   â”œâ”€â”€ openai.py       # OpenAI provider
â”‚   â”‚   â”œâ”€â”€ gemini.py       # Gemini provider
â”‚   â”‚   â”œâ”€â”€ openrouter.py   # OpenRouter provider
â”‚   â”‚   â””â”€â”€ local.py         # Local model provider
â”‚   â”‚
â”‚   â”œâ”€â”€ vector_store/       # Vector store abstraction
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ interface.py    # Vector store interface
â”‚   â”‚   â”œâ”€â”€ chroma.py       # Chroma implementation
â”‚   â”‚   â”œâ”€â”€ qdrant.py        # Qdrant implementation
â”‚   â”‚   â””â”€â”€ faiss.py         # FAISS implementation
â”‚   â”‚
â”‚   â”œâ”€â”€ graph/              # Knowledge graph layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ schema.py       # DRG schema (existing)
â”‚   â”‚   â”œâ”€â”€ extract.py      # Entity/relation extraction (existing)
â”‚   â”‚   â”œâ”€â”€ kg_core.py      # EnhancedKG class (KGNode, KGEdge, Cluster)
â”‚   â”‚   â”œâ”€â”€ visualization.py # KG visualization (Mermaid, PyVis)
â”‚   â”‚   â”œâ”€â”€ community_report.py # Community report generation
â”‚   â”‚   â””â”€â”€ storage.py      # Graph storage abstraction
â”‚   â”‚
â”‚   â”œâ”€â”€ retrieval/          # Retrieval layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag.py          # Classic RAG retrieval
â”‚   â”‚   â”œâ”€â”€ graphrag.py     # GraphRAG retrieval (KG traversal)
â”‚   â”‚   â”œâ”€â”€ drg_search.py   # DRG search algorithms
â”‚   â”‚   â””â”€â”€ hybrid.py        # Hybrid RAG + GraphRAG
â”‚   â”‚
â”‚   â”œâ”€â”€ clustering/         # Clustering layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ algorithms.py   # Clustering algorithms (Louvain, Leiden, Spectral)
â”‚   â”‚   â””â”€â”€ summarization.py # Cluster summarization
â”‚   â”‚
â”‚   â”œâ”€â”€ optimizer/          # DSPy optimizer module
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ optimizer.py    # DRGOptimizer class
â”‚   â”‚   â””â”€â”€ metrics.py      # Evaluation metrics
â”‚   â”‚
â”‚   â””â”€â”€ mcp_api.py          # MCP API interface
â”‚
â”œâ”€â”€ docs/                   # Documentation (NO CODE)
â”‚   â”œâ”€â”€ project_complete_guide.md  # Bu dosya
â”‚   â”œâ”€â”€ chunking_strategy.md
â”‚   â”œâ”€â”€ schema_design.md
â”‚   â”œâ”€â”€ pipeline_overview.md
â”‚   â”œâ”€â”€ drg_search.md
â”‚   â”œâ”€â”€ clustering_summarization.md
â”‚   â”œâ”€â”€ optimizer_design.md
â”‚   â””â”€â”€ mcp_integration.md
â”‚
â”œâ”€â”€ examples/               # Usage examples
â”‚   â”œâ”€â”€ graphrag_pipeline_example.py  # Tam GraphRAG pipeline
â”‚   â”œâ”€â”€ mcp_demo.py         # MCP API demo
â”‚   â””â”€â”€ optimizer_demo.py   # Optimizer demo
â”‚
â”œâ”€â”€ tests/                  # Test suite
â”‚   â”œâ”€â”€ test_basic.py       # Temel testler (tÃ¼m provider'lar iÃ§in)
â”‚   â””â”€â”€ multi_dataset/
â”‚       â””â”€â”€ evaluation.py   # Multi-dataset evaluation
â”‚
â”œâ”€â”€ inputs/                  # Input dosyalarÄ± (sayÄ± baÅŸta format)
â”‚   â”œâ”€â”€ 1example_text.txt
â”‚   â”œâ”€â”€ 1example_schema.json (opsiyonel - yoksa otomatik oluÅŸturulur)
â”‚   â”œâ”€â”€ 2example_text.txt
â”‚   â”œâ”€â”€ 3example_text.txt
â”‚   â””â”€â”€ 4example_text.txt
â”‚
â”œâ”€â”€ outputs/                 # Generated outputs
â”‚   â”œâ”€â”€ 1example_schema.json
â”‚   â”œâ”€â”€ 1example_kg.json
â”‚   â”œâ”€â”€ 1example_community_reports.json
â”‚   â””â”€â”€ 1example_summary.json
â”‚
â”œâ”€â”€ pyproject.toml          # Project configuration
â””â”€â”€ README.md               # Project README
```

### ModÃ¼l AÃ§Ä±klamalarÄ±

#### `drg/schema.py`
Schema tanÄ±mlarÄ± iÃ§in temel sÄ±nÄ±flar:
- `Entity`: Basit entity tanÄ±mÄ±
- `Relation`: Relation tanÄ±mÄ± (name, source, target, description, detail)
  - `description`: BaÄŸlantÄ± sebebi/tÃ¼rÃ¼ aÃ§Ä±klamasÄ±
  - `detail`: BaÄŸlantÄ± detayÄ± (tek cÃ¼mleyle neden baÄŸlantÄ±lÄ± olduÄŸu)
- `DRGSchema`: Legacy schema class (backward compatibility)
- `EntityType`: GeliÅŸmiÅŸ entity tanÄ±mÄ± (name, description, examples, properties)
- `RelationGroup`: Ä°liÅŸkili relation'larÄ± semantic olarak gruplama
- `EnhancedDRGSchema`: GeliÅŸmiÅŸ schema class (entity_types, relation_groups, auto_discovery)

#### `drg/extract.py`
DSPy kullanarak entity ve relation extraction:
- `KGExtractor`: Ana extraction class (chunk-based processing iÃ§in kullanÄ±lÄ±r)
- `extract_typed()`: Typed entity ve relation extraction
- `extract_triples()`: Sadece relation extraction (backward compatibility)
- `generate_schema_from_text()`: Metinden otomatik EnhancedDRGSchema oluÅŸturma
- `_configure_llm_auto()`: Otomatik LLM konfigÃ¼rasyonu (OpenRouter, OpenAI, vb.)

#### `drg/chunking/`
Metin parÃ§alama stratejileri:
- `TokenBasedChunker`: Token sayÄ±sÄ±na gÃ¶re chunking
- `SentenceBasedChunker`: CÃ¼mle sÄ±nÄ±rlarÄ±na gÃ¶re chunking
- `ChunkValidator`: Chunk doÄŸrulama
- `create_chunker()`: Factory function (preset desteÄŸi ile)
  - Preset'ler: "graphrag", "medium"

#### `drg/embedding/`
Embedding provider'larÄ±:
- `OpenAIEmbeddingProvider`: OpenAI embedding'leri
- `GeminiEmbeddingProvider`: Google Gemini embedding'leri
- `OpenRouterEmbeddingProvider`: OpenRouter embedding'leri
- `LocalEmbeddingProvider`: Local model embedding'leri (sentence-transformers)

#### `drg/graph/kg_core.py`
Enhanced Knowledge Graph yapÄ±sÄ±:
- `KGNode`: Graph node (id, type, properties, metadata, embedding)
- `KGEdge`: Graph edge (source, target, relationship_type, relationship_detail, metadata)
- `Cluster`: Cluster tanÄ±mÄ± (id, node_ids, metadata)
- `EnhancedKG`: Ana KG class (nodes, edges, clusters, community reports)

#### `drg/retrieval/`
Retrieval stratejileri:
- `RAGRetriever`: Classic RAG (vector similarity search)
- `GraphRAGRetriever`: GraphRAG (KG traversal + community reports)
- `DRGSearch`: DRG search algorithms
- `HybridRetriever`: RAG + GraphRAG hybrid

#### `drg/clustering/`
Clustering algoritmalarÄ±:
- `LouvainClustering`: Louvain community detection (python-louvain gerekli)
- `LeidenClustering`: Leiden algorithm (leidenalg, python-igraph gerekli)
- `SpectralClustering`: Spectral clustering (scikit-learn gerekli)
- `create_clustering_algorithm()`: Factory function
- EnhancedKG ve NetworkX graph formatlarÄ±nÄ± destekler
- Self-loop edge'leri otomatik filtreler

#### `drg/optimizer/`
DSPy optimizer desteÄŸi:
- `DRGOptimizer`: Optimizer wrapper class
- `ExtractionMetrics`: Evaluation metrics (precision, recall, F1)
- `BootstrapFewShot`, `MIPRO`, `COPRO`, `LabeledFewShot` desteÄŸi

---

## Declarative YapÄ±

### Declarative YaklaÅŸÄ±mÄ±n AvantajlarÄ±

1. **Basitlik**: KullanÄ±cÄ± sadece "ne" istediÄŸini tanÄ±mlar
2. **Esneklik**: Sistem otomatik olarak en iyi yÃ¶ntemi seÃ§er
3. **BakÄ±m KolaylÄ±ÄŸÄ±**: Implementation detaylarÄ± gizlenir
4. **Test Edilebilirlik**: Schema'lar kolayca test edilebilir

### DRG'de Declarative YapÄ±

#### 1. Schema TanÄ±mlama

```python
# Basit schema
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)

# GeliÅŸmiÅŸ schema (description'lar ile)
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[
        Relation(
            "produces", 
            "Company", 
            "Product",
            description="Bu iliÅŸki, bir ÅŸirketin belirli bir Ã¼rÃ¼nÃ¼ Ã¼rettiÄŸini, geliÅŸtirdiÄŸini veya piyasaya sÃ¼rdÃ¼ÄŸÃ¼nÃ¼ gÃ¶sterir. ÃœrÃ¼n, ÅŸirketin ana faaliyet alanÄ± veya Ã¼retim hattÄ±nÄ±n bir parÃ§asÄ± olabilir."
        )
    ]
)
```

#### 2. JSON Schema FormatÄ±

Schema'lar JSON formatÄ±nda da tanÄ±mlanabilir:

```json
{
  "entities": [
    {
      "name": "Company",
      "description": "Business organizations and corporations"
    },
    {
      "name": "Product",
      "description": "Products, devices, goods"
    }
  ],
  "relations": [
    {
      "name": "produces",
      "source": "Company",
      "target": "Product",
      "description": "Bu iliÅŸki, bir ÅŸirketin belirli bir Ã¼rÃ¼nÃ¼ Ã¼rettiÄŸini gÃ¶sterir..."
    }
  ]
}
```

#### 3. Otomatik Extraction

Schema tanÄ±mlandÄ±ktan sonra, extraction otomatik olarak yapÄ±lÄ±r:

```python
# Sadece schema ve metin yeterli
text = "Apple produces iPhone, iPad, and Mac computers."
entities, triples = extract_typed(text, schema)

# Sistem otomatik olarak:
# 1. LLM'i konfigÃ¼re eder
# 2. Entity extraction yapar
# 3. Relation extraction yapar
# 4. SonuÃ§larÄ± dÃ¶ndÃ¼rÃ¼r
```

### Declarative vs Imperative KarÅŸÄ±laÅŸtÄ±rma

**Imperative YaklaÅŸÄ±m** (Geleneksel):
```python
# AdÄ±m adÄ±m manuel iÅŸlem
text = "Apple produces iPhone"
# 1. Metni tokenize et
tokens = tokenize(text)
# 2. NER (Named Entity Recognition) Ã§alÄ±ÅŸtÄ±r
entities = ner_model.predict(tokens)
# 3. Relation extraction Ã§alÄ±ÅŸtÄ±r
relations = relation_model.predict(tokens, entities)
# 4. KG oluÅŸtur
kg = build_kg(entities, relations)
```

**Declarative YaklaÅŸÄ±m** (DRG):
```python
# Sadece ne istediÄŸinizi tanÄ±mlayÄ±n
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)
# Sistem otomatik olarak halleder
entities, triples = extract_typed(text, schema)
kg = EnhancedKG.from_typed(entities, triples)
```

---

## Pipeline Mimarisi

### Tam GraphRAG Pipeline

DRG'nin tam pipeline'Ä± ÅŸu adÄ±mlardan oluÅŸur:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1. CHUNKING                              â”‚
â”‚  Metin â†’ Token/Sentence-based Chunking â†’ Chunks            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              2. KNOWLEDGE GRAPH EXTRACTION                  â”‚
â”‚  Chunks â†’ DSPy Extraction â†’ Entities + Relations            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚             3. ENHANCED KG OLUÅTURMA                        â”‚
â”‚  Entities + Relations â†’ KGNode + KGEdge â†’ EnhancedKG       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           4. ENTITY EMBEDDING'LERÄ° EKLEME                    â”‚
â”‚  EnhancedKG â†’ Embedding Provider â†’ Node Embeddings         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        5. CLUSTERING VE COMMUNITY REPORTS                   â”‚
â”‚  EnhancedKG â†’ Clustering Algorithm â†’ Clusters             â”‚
â”‚  Clusters â†’ Community Report Generator â†’ Reports           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              6. GRAPHRAG RETRIEVAL                          â”‚
â”‚  Query â†’ Seed Entity Finding â†’ Graph Traversal             â”‚
â”‚  Graph Traversal + Community Reports â†’ Context            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### AdÄ±m AdÄ±m AÃ§Ä±klama

#### 1. Chunking (ParÃ§alama)

**AmaÃ§**: Uzun metinleri iÅŸlenebilir parÃ§alara bÃ¶lmek

**Stratejiler**:
- **Token-based**: Token sayÄ±sÄ±na gÃ¶re (Ã¶rn: 200 token)
- **Sentence-based**: CÃ¼mle sÄ±nÄ±rlarÄ±na gÃ¶re
- **Semantic**: Anlamsal benzerliÄŸe gÃ¶re

**Ã–rnek**:
```python
chunker = create_chunker(
    strategy="token_based",
    chunk_size=200,
    overlap_ratio=0.15
)
chunks = chunker.chunk(
    text=text,
    origin_dataset="apple_corpus",
    origin_file="apple_history.txt"
)
```

**Ã‡Ä±ktÄ±**: Chunk listesi (her chunk: text, token_count, chunk_id, metadata)

#### 2. Knowledge Graph Extraction

**AmaÃ§**: Chunk'lardan entity ve relation Ã§Ä±karmak

**YÃ¶ntem**: DSPy framework kullanarak LLM ile extraction

**SÃ¼reÃ§**:
1. Schema'dan dinamik DSPy signature'larÄ± oluÅŸturulur
2. **Chunk-based Processing**: Her chunk Ã¼zerinde baÄŸÄ±msÄ±z extraction yapÄ±lÄ±r
   - Her chunk iÃ§in entity extraction
   - Her chunk iÃ§in relation extraction (entity'ler context olarak verilir)
3. SonuÃ§lar birleÅŸtirilir (duplicate entity ve relation'lar otomatik filtrelenir)
4. Self-loop edge'ler filtrelenir (source == target olan edge'ler atlanÄ±r)

**Ã–rnek**:
```python
extractor = KGExtractor(schema)
all_entities = set()
all_triples = set()

for chunk in chunks:
    result = extractor.forward(chunk.text)
    entities = json.loads(result.entities)  # [[name, type], ...]
    relations = json.loads(result.relations)  # [[source, relation, target], ...]
    
    # Unique entity ve relation'larÄ± topla
    all_entities.update([(e[0], e[1]) for e in entities])
    all_triples.update([(r[0], r[1], r[2]) for r in relations])
```

**Ã‡Ä±ktÄ±**: Unique entity listesi ve relation listesi (triples)

#### 3. Enhanced KG OluÅŸturma

**AmaÃ§**: Entity ve relation'lardan EnhancedKG yapÄ±sÄ± oluÅŸturmak

**YapÄ±**:
- **KGNode**: id, type, properties, metadata, embedding
- **KGEdge**: source, target, relationship_type, relationship_detail, metadata

**Ã–rnek**:
```python
enhanced_kg = EnhancedKG()

# Node'lar ekle
for entity_name, entity_type in entities_list:
    node = KGNode(id=entity_name, type=entity_type)
    enhanced_kg.add_node(node)

# Edge'ler ekle
for source, relation, target in triples_list:
    edge = KGEdge(
        source=source,
        target=target,
        relationship_type=relation,
        relationship_detail=relation_descriptions.get(relation, f"{source} {relation} {target}"),
        metadata={}
    )
    enhanced_kg.add_edge(edge)
```

**Ã‡Ä±ktÄ±**: EnhancedKG objesi (nodes, edges, clusters)

#### 4. Entity Embedding'leri Ekleme

**AmaÃ§**: Node'lara embedding vektÃ¶rleri eklemek (GraphRAG iÃ§in gerekli)

**Provider'lar**:
- OpenAI (text-embedding-3-small, text-embedding-3-large)
- Gemini (text-embedding-004)
- OpenRouter (Ã§eÅŸitli modeller)
- Local (sentence-transformers)

**Ã–rnek**:
```python
embedding_provider = create_embedding_provider(
    provider="openrouter",
    model="openrouter/text-embedding-ada-002"
)
entity_texts = {node_id: node_id for node_id in enhanced_kg.nodes.keys()}
enhanced_kg.add_entity_embeddings(embedding_provider, entity_texts)
```

**Ã‡Ä±ktÄ±**: EnhancedKG (her node'da embedding vektÃ¶rÃ¼)

#### 5. Clustering ve Community Reports

**AmaÃ§**: Graph'u cluster'lara bÃ¶lmek ve her cluster iÃ§in Ã¶zet rapor oluÅŸturmak

**Clustering AlgoritmalarÄ±**:
- **Louvain**: Community detection (python-louvain paketi gerekli)
- **Leiden**: Louvain'in geliÅŸtirilmiÅŸ versiyonu (leidenalg, python-igraph gerekli)
- **Spectral**: Spectral clustering (scikit-learn gerekli)

**SÃ¼reÃ§**:
1. EnhancedKG NetworkX graph formatÄ±na Ã§evrilir
2. SeÃ§ilen algoritma ile clustering yapÄ±lÄ±r
3. Cluster'lar EnhancedKG'ye eklenir
4. Her cluster iÃ§in community report oluÅŸturulur

**Community Reports Ä°Ã§eriÄŸi**:
- **Top Actors**: Cluster'daki Ã¶nemli entity'ler (entity frequency'e gÃ¶re)
- **Top Relationships**: Cluster'daki Ã¶nemli iliÅŸkiler (relationship frequency'e gÃ¶re)
- **Themes**: Cluster'Ä±n temalarÄ± (top actors ve relationships'ten Ã§Ä±karÄ±lÄ±r)
- **Summary**: Cluster Ã¶zeti

**Ã–rnek**:
```python
clustering_algorithm = create_clustering_algorithm(algorithm="louvain")
G = nx.Graph()

# EnhancedKG'yi NetworkX'e Ã§evir
for node_id in enhanced_kg.nodes.keys():
    G.add_node(node_id)
for edge in enhanced_kg.edges:
    G.add_edge(edge.source, edge.target)

# Clustering yap
clusters = clustering_algorithm.cluster(G)

# Cluster'larÄ± EnhancedKG'ye ekle
for cluster in clusters:
    kg_cluster = Cluster(
        id=f"cluster_{cluster.cluster_id}",
        node_ids=set(cluster.nodes),
        metadata=cluster.metadata
    )
    enhanced_kg.add_cluster(kg_cluster)

# Community reports oluÅŸtur
report_generator = CommunityReportGenerator(enhanced_kg)
reports = report_generator.generate_all_reports()
```

**Ã‡Ä±ktÄ±**: Cluster listesi ve Community report listesi

#### 6. GraphRAG Retrieval

**AmaÃ§**: Query'ye gÃ¶re KG'den ilgili bilgileri retrieve etmek

**SÃ¼reÃ§**:
1. **Seed Entity Finding**: Query'yi embed et, KG'deki node embedding'leri ile karÅŸÄ±laÅŸtÄ±r, en benzer node'larÄ± bul
2. **Graph Traversal**: Seed entity'lerden baÅŸlayarak graph'Ä± traverse et
3. **Subgraph Extraction**: Ä°lgili node ve edge'leri iÃ§eren subgraph oluÅŸtur
4. **Community Report Integration**: Ä°lgili cluster'larÄ±n community report'larÄ±nÄ± ekle
5. **Context Assembly**: TÃ¼m bilgileri context olarak birleÅŸtir

**Ã–rnek**:
```python
retriever = create_graphrag_retriever(
    kg=enhanced_kg,
    embedding_provider=embedding_provider
)
context = retriever.retrieve(
    query="What products does Apple produce?",
    max_hops=2,
    top_k=5
)
```

**Ã‡Ä±ktÄ±**: RetrievalContext (entities, relationships, community_reports, chunks)

### Pipeline Ã‡Ä±ktÄ±larÄ±

Pipeline Ã§alÄ±ÅŸtÄ±ktan sonra ÅŸu dosyalar oluÅŸturulur:

- `outputs/{example_name}_schema.json`: KullanÄ±lan schema (Enhanced veya Legacy format)
- `outputs/{example_name}_kg.json`: OluÅŸturulan Knowledge Graph (EnhancedKG formatÄ±nda)
- `outputs/{example_name}_community_reports.json`: Community report'lar (clustering yapÄ±ldÄ±ysa)
- `outputs/{example_name}_summary.json`: Pipeline Ã¶zeti (chunk sayÄ±sÄ±, node sayÄ±sÄ±, cluster sayÄ±sÄ±, vb.)

**Not**: Dosya isimlendirme formatÄ± sayÄ± baÅŸta kullanÄ±lÄ±r (Ã¶rn: `1example`, `2example`, `3example`). Pipeline hem eski format (`example1`) hem de yeni format (`1example`) destekler.

---

## BileÅŸenler ve Metodlar

### Schema BileÅŸenleri

#### Entity ve Relation TanÄ±mlarÄ±

```python
# Basit Entity
entity = Entity("Company")

# Basit Relation
relation = Relation(
    name="produces",
    source="Company",
    target="Product",
    description="Åirket Ã¼rÃ¼n Ã¼retir"  # Opsiyonel aÃ§Ä±klayÄ±cÄ± cÃ¼mle
)

# DRGSchema
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)
```

#### Enhanced Schema BileÅŸenleri

```python
# EntityType (geliÅŸmiÅŸ entity tanÄ±mÄ±)
entity_type = EntityType(
    name="Company",
    description="Business organizations and corporations",
    examples=["Apple", "Google", "Microsoft"],
    properties={"industry": "tech"}
)

# RelationGroup (iliÅŸkili relation'larÄ± gruplama)
relation_group = RelationGroup(
    name="production",
    description="How companies create products",
    relations=[
        Relation(
            name="produces",
            src="Company",
            dst="Product",
            description="Relationship type explanation - why this relationship exists",
            detail="Specific detail about why/how entities are connected"
        ),
        Relation(
            name="manufactures",
            src="Company",
            dst="Product",
            description="Manufacturing relationship",
            detail="Companies create products through manufacturing processes"
        )
    ],
    examples=[]  # Opsiyonel: Ã–rnek metinler ve entity/relation'lar
)

# EnhancedDRGSchema
enhanced_schema = EnhancedDRGSchema(
    entity_types=[entity_type],
    relation_groups=[relation_group],
    auto_discovery=True  # Schema'da tanÄ±mlÄ± olmayan relation'larÄ± da bul
)
```

### Extraction MetodlarÄ±

#### `extract_typed(text, schema)`

Metinden typed entity ve relation Ã§Ä±karÄ±r.

**Parametreler**:
- `text` (str): Ä°ÅŸlenecek metin
- `schema` (DRGSchema | EnhancedDRGSchema): Åema tanÄ±mÄ±

**DÃ¶ndÃ¼rÃ¼r**:
- `Tuple[List[Tuple[str, str]], List[Tuple[str, str, str]]]`: (entities, triples)
  - entities: `[(entity_name, entity_type), ...]`
  - triples: `[(source, relation, target), ...]`

**Ã–rnek**:
```python
text = "Apple produces iPhone. Tim Cook is the CEO of Apple."
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product"), Entity("Person")],
    relations=[
        Relation("produces", "Company", "Product"),
        Relation("ceo_of", "Person", "Company")
    ]
)

entities, triples = extract_typed(text, schema)
# entities: [("Apple", "Company"), ("iPhone", "Product"), ("Tim Cook", "Person")]
# triples: [("Apple", "produces", "iPhone"), ("Tim Cook", "ceo_of", "Apple")]
```

#### `KGExtractor`

DSPy module olarak extraction yapar.

**KullanÄ±m**:
```python
extractor = KGExtractor(schema)
result = extractor.forward(text)
entities = json.loads(result.entities)
relations = json.loads(result.relations)
```

**Ã–zellikler**:
- Rate limit handling (otomatik retry)
- Exponential backoff
- JSON string parsing (Gemini uyumluluÄŸu iÃ§in)

### Chunking MetodlarÄ±

#### `create_chunker(strategy, chunk_size, overlap_ratio, preset)`

Chunker oluÅŸturur.

**Parametreler**:
- `strategy` (str): "token_based" | "sentence_based" | "semantic"
- `chunk_size` (int): Chunk boyutu (token veya cÃ¼mle sayÄ±sÄ±)
- `overlap_ratio` (float): Chunk'lar arasÄ± overlap oranÄ± (0.0-1.0)
- `preset` (str): Preset ismi (Ã¶rn: "graphrag") - preset belirtilirse diÄŸer parametreler override edilir

**Preset'ler**:
- `"graphrag"`: GraphRAG iÃ§in optimize edilmiÅŸ chunking (token_based, chunk_size=200, overlap_ratio=0.15)
- `"medium"`: Orta boyutlu chunk'lar iÃ§in (token_based, chunk_size=500, overlap_ratio=0.1)

**Ã–rnek**:
```python
# Preset kullanarak
chunker = create_chunker(preset="graphrag")
chunks = chunker.chunk(text, origin_dataset="corpus", origin_file="file.txt")

# Manuel parametrelerle
chunker = create_chunker(
    strategy="token_based",
    chunk_size=200,
    overlap_ratio=0.15
)
chunks = chunker.chunk(text, origin_dataset="corpus", origin_file="file.txt")
```

### Embedding MetodlarÄ±

#### `create_embedding_provider(provider, model, **kwargs)`

Embedding provider oluÅŸturur.

**Parametreler**:
- `provider` (str): "openai" | "gemini" | "openrouter" | "local"
- `model` (str): Model adÄ± (Ã¶rn: "text-embedding-3-small")
- `**kwargs`: Provider-specific parametreler

**Ã–rnek**:
```python
# OpenAI
provider = create_embedding_provider(
    provider="openai",
    model="text-embedding-3-small"
)

# OpenRouter
provider = create_embedding_provider(
    provider="openrouter",
    model="openrouter/text-embedding-ada-002"
)

# Local
provider = create_embedding_provider(
    provider="local",
    model="sentence-transformers/all-MiniLM-L6-v2"
)

# Embedding yap
embedding = provider.embed("Apple")
embeddings = provider.embed_batch(["Apple", "iPhone"])
```

### Knowledge Graph MetodlarÄ±

#### `EnhancedKG`

Ana Knowledge Graph class'Ä±.

**Metodlar**:
- `add_node(node)`: Node ekle
- `add_edge(edge)`: Edge ekle
- `add_cluster(cluster)`: Cluster ekle
- `add_entity_embeddings(provider, entity_texts)`: Entity embedding'leri ekle
- `to_dict()`: Dictionary'ye Ã§evir
- `to_json()`: JSON string'e Ã§evir

**Ã–rnek**:
```python
kg = EnhancedKG()

# Node ekle
node = KGNode(id="Apple", type="Company", properties={}, metadata={})
kg.add_node(node)

# Edge ekle
edge = KGEdge(
    source="Apple",
    target="iPhone",
    relationship_type="produces",
    relationship_detail="Apple iPhone Ã¼retir",
    metadata={}
)
kg.add_edge(edge)

# Embedding ekle
provider = create_embedding_provider(provider="openai")
entity_texts = {"Apple": "Apple", "iPhone": "iPhone"}
kg.add_entity_embeddings(provider, entity_texts)
```

### Retrieval MetodlarÄ±

#### `create_graphrag_retriever(kg, embedding_provider)`

GraphRAG retriever oluÅŸturur.

**Parametreler**:
- `kg` (EnhancedKG): Knowledge Graph
- `embedding_provider` (EmbeddingProvider): Embedding provider

**Ã–rnek**:
```python
retriever = create_graphrag_retriever(
    kg=enhanced_kg,
    embedding_provider=embedding_provider
)

context = retriever.retrieve(
    query="What products does Apple produce?",
    max_hops=2,
    top_k=5
)

# Context iÃ§eriÄŸi:
# - entities: List of entities
# - relationships: List of relationships
# - community_reports: List of community reports
# - chunks: List of relevant chunks
```

### Clustering MetodlarÄ±

#### `create_clustering_algorithm(algorithm)`

Clustering algorithm oluÅŸturur.

**Parametreler**:
- `algorithm` (str): "louvain" | "leiden" | "spectral"

**Ã–rnek**:
```python
algorithm = create_clustering_algorithm(algorithm="louvain")
G = nx.Graph()  # NetworkX graph
# Graph'u doldur
clusters = algorithm.cluster(G)  # List of node sets
```

---

## DiÄŸer KG Sistemlerinden FarklarÄ±

### 1. Declarative vs Imperative

**Geleneksel KG Sistemleri**:
- Imperative yaklaÅŸÄ±m: AdÄ±m adÄ±m manuel iÅŸlem
- Kod yazma gereksinimi
- Implementation detaylarÄ±na hakim olma zorunluluÄŸu

**DRG**:
- Declarative yaklaÅŸÄ±m: Sadece schema tanÄ±mlama
- Minimal kod
- Implementation detaylarÄ± gizli

### 2. Dataset-Agnostic TasarÄ±m

**Geleneksel KG Sistemleri**:
- Genellikle belirli bir domain iÃ§in optimize edilmiÅŸ
- Domain-specific adaptasyon gerektirir

**DRG**:
- Herhangi bir veri kaynaÄŸÄ±ndan baÄŸÄ±msÄ±z
- Pluggable components ile kolay adaptasyon
- Domain-specific optimizasyonlar core pipeline'Ä± deÄŸiÅŸtirmeden eklenebilir

### 3. GraphRAG DesteÄŸi

**Geleneksel KG Sistemleri**:
- Genellikle sadece KG oluÅŸturma
- Retrieval iÃ§in ayrÄ± sistemler gerekir

**DRG**:
- KG oluÅŸturma + GraphRAG retrieval
- End-to-end pipeline
- Community reports ile zengin context

### 4. LLM Entegrasyonu

**Geleneksel KG Sistemleri**:
- Genellikle rule-based veya ML-based extraction
- LLM entegrasyonu manuel

**DRG**:
- DSPy framework ile native LLM entegrasyonu
- Otomatik LLM konfigÃ¼rasyonu
- Multi-provider desteÄŸi (OpenAI, Gemini, Anthropic, vb.)

### 5. Relationship Description DesteÄŸi

**Geleneksel KG Sistemleri**:
- Genellikle sadece relation type (Ã¶rn: "produces")
- AÃ§Ä±klayÄ±cÄ± cÃ¼mleler yok

**DRG**:
- Relation description desteÄŸi
- Her relation iÃ§in aÃ§Ä±klayÄ±cÄ± cÃ¼mle
- Daha zengin semantic bilgi

### 6. Monolithic-Modular Mimarisi

**Geleneksel KG Sistemleri**:
- Genellikle tamamen modÃ¼ler (ayrÄ± paketler)
- Veya tamamen monolithic (tek blok)

**DRG**:
- Monolithic-modular hybrid
- Tek deployment unit
- ModÃ¼ler test edilebilirlik

### 7. Enhanced Schema

**Geleneksel KG Sistemleri**:
- Genellikle basit entity-relation tanÄ±mlarÄ±
- Gruplama ve property desteÄŸi sÄ±nÄ±rlÄ±

**DRG**:
- Enhanced schema (EntityType, RelationGroup, EntityGroup, PropertyGroup)
- Zengin metadata desteÄŸi
- Auto-discovery Ã¶zelliÄŸi

---

## KullanÄ±m Ã–rnekleri

### Basit KullanÄ±m

```python
from drg import Entity, Relation, DRGSchema, extract_typed, EnhancedKG, KGNode, KGEdge

# Schema tanÄ±mla
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)

# Metinden Ã§Ä±karÄ±m yap
text = "Apple produces iPhone, iPad, and Mac computers."
entities, triples = extract_typed(text, schema)

# EnhancedKG oluÅŸtur
kg = EnhancedKG()
for entity_name, entity_type in entities:
    kg.add_node(KGNode(id=entity_name, type=entity_type))

for source, relation, target in triples:
    kg.add_edge(KGEdge(
        source=source,
        target=target,
        relationship_type=relation,
        relationship_detail=f"{source} {relation} {target}",
        metadata={}
    ))

# JSON'a Ã§evir
print(kg.to_json(indent=2))
```

### Tam GraphRAG Pipeline

```python
from drg.chunking import create_chunker
from drg.embedding import create_embedding_provider
from drg.extract import KGExtractor, _configure_llm_auto
from drg.schema import DRGSchema, Entity, Relation
from drg.graph.kg_core import EnhancedKG, KGNode, KGEdge
from drg.retrieval import create_graphrag_retriever

# 1. Chunking
chunker = create_chunker(strategy="token_based", chunk_size=200)
chunks = chunker.chunk(text, origin_dataset="corpus", origin_file="file.txt")

# 2. LLM konfigÃ¼rasyonu
_configure_llm_auto()

# 3. KG Extraction
schema = DRGSchema(
    entities=[Entity("Company"), Entity("Product")],
    relations=[Relation("produces", "Company", "Product")]
)
extractor = KGExtractor(schema)
result = extractor.forward(text)
entities = json.loads(result.entities)
triples = json.loads(result.relations)

# 4. EnhancedKG oluÅŸtur
kg = EnhancedKG()
# ... node ve edge ekleme

# 5. Embedding ekle
provider = create_embedding_provider(provider="openai")
kg.add_entity_embeddings(provider, entity_texts)

# 6. GraphRAG Retrieval
retriever = create_graphrag_retriever(kg=kg, embedding_provider=provider)
context = retriever.retrieve(query="What products does Apple produce?")
```

### JSON Schema ile KullanÄ±m

```python
import json
from drg.schema import DRGSchema, Entity, Relation

# Schema'yÄ± JSON'dan yÃ¼kle
with open("schema.json", "r") as f:
    schema_data = json.load(f)

entities = [Entity(e["name"]) for e in schema_data["entities"]]
relations = [
    Relation(
        r["name"],
        r["source"],
        r["target"],
        description=r.get("description", "")
    )
    for r in schema_data["relations"]
]

schema = DRGSchema(entities=entities, relations=relations)
```

### Pipeline Example KullanÄ±mÄ±

```bash
# Pipeline'Ä± Ã§alÄ±ÅŸtÄ±r (sayÄ± baÅŸta format)
python examples/graphrag_pipeline_example.py 1
python examples/graphrag_pipeline_example.py 1example
python examples/graphrag_pipeline_example.py example1  # Otomatik 1example'a Ã§evrilir

# Ã‡Ä±ktÄ±lar:
# - outputs/1example_schema.json
# - outputs/1example_kg.json
# - outputs/1example_community_reports.json (clustering yapÄ±ldÄ±ysa)
# - outputs/1example_summary.json
```

### Otomatik Schema Generation

Metin verildiÄŸinde, schema yoksa otomatik olarak EnhancedDRGSchema oluÅŸturulur:

```python
from drg.extract import generate_schema_from_text

# Metinden otomatik schema oluÅŸtur
text = "Apple Inc. is a technology company..."
schema = generate_schema_from_text(text)

# Schema iÃ§eriÄŸi:
# - entity_types: Properties ve examples ile zengin entity tanÄ±mlarÄ±
# - relation_groups: Semantic olarak gruplandÄ±rÄ±lmÄ±ÅŸ relation'lar
# - Her relation iÃ§in description (baÄŸlantÄ± sebebi) ve detail (baÄŸlantÄ± detayÄ±)
```

---

## GeliÅŸtirme ve KatkÄ±da Bulunma

### GeliÅŸtirme OrtamÄ± Kurulumu

```bash
# Projeyi klonla
git clone <repository-url>
cd DRG

# Virtual environment oluÅŸtur
python -m venv venv
source venv/bin/activate  # macOS/Linux
# veya
venv\Scripts\activate  # Windows

# Projeyi kur
pip install -e .

# Dependencies kur
pip install -r requirements.txt
```

### Test Ã‡alÄ±ÅŸtÄ±rma

```bash
# TÃ¼m testler
pytest tests/

# Belirli bir test
pytest tests/test_basic.py::test_extract_entities_and_relations_with_openai

# API key olmadan yapÄ± testleri
python examples/graphrag_pipeline_example.py example1
```

### Kod StandartlarÄ±

- **Type Hints**: TÃ¼m fonksiyonlar type hint'li
- **Docstrings**: Google style docstrings
- **Linting**: ruff, mypy, black
- **Interface-First**: Ã–nce interface, sonra implementation

### Yeni BileÅŸen Ekleme

1. Interface tanÄ±mla (`drg/<module>/interface.py`)
2. Implementation yap (`drg/<module>/<provider>.py`)
3. Factory function ekle (`drg/<module>/__init__.py`)
4. Test yaz (`tests/test_<module>.py`)
5. DokÃ¼mantasyon gÃ¼ncelle (`docs/<module>.md`)

---

## SonuÃ§

DRG, modern LLM teknolojilerini kullanarak declarative bir yaklaÅŸÄ±mla Knowledge Graph oluÅŸturma ve GraphRAG retrieval yapma imkanÄ± sunan, dataset-agnostic bir Python kÃ¼tÃ¼phanesidir. Proje, research-grade kalitede, community publication-ready bir yapÄ±da tasarlanmÄ±ÅŸtÄ±r.

### Projenin GÃ¼Ã§lÃ¼ YÃ¶nleri

1. âœ… **Declarative YaklaÅŸÄ±m**: Minimal kod, maksimum esneklik
2. âœ… **Dataset-Agnostic**: Herhangi bir veri kaynaÄŸÄ±ndan baÄŸÄ±msÄ±z
3. âœ… **GraphRAG DesteÄŸi**: End-to-end GraphRAG pipeline
4. âœ… **Multi-Provider**: OpenAI, Gemini, Anthropic, OpenRouter, vb.
5. âœ… **Enhanced Schema**: Zengin metadata ve aÃ§Ä±klama desteÄŸi
6. âœ… **Modular Architecture**: Kolay test edilebilirlik ve geniÅŸletilebilirlik

### Gelecek GeliÅŸtirmeler

- [ ] Neo4j, ArangoDB gibi graph database desteÄŸi
- [ ] Daha fazla clustering algoritmasÄ±
- [ ] Real-time KG update mekanizmasÄ±
- [ ] Web UI
- [ ] Docker containerization
- [ ] Cloud deployment (AWS, GCP, Azure)

---

**Not**: Bu dokÃ¼mantasyon, DRG projesinin mevcut durumunu (v0.1.0a0) yansÄ±tmaktadÄ±r. API deÄŸiÅŸiklikleri olabilir.

